{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/admin1/.local/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (1.56.2)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: packaging in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (0.33.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/admin1/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/admin1/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/admin1/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/admin1/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/admin1/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/admin1/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/admin1/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/admin1/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/admin1/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/admin1/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/admin1/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/admin1/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.2.0 requires jinja2, which is not installed.\n",
      "torch 2.2.0 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed typing-extensions-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-22 18:36:48.044879: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-22 18:36:48.069645: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-22 18:36:48.218191: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-22 18:36:48.218999: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-22 18:36:48.889829: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import re, os, sys\n",
    "import copy\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import psutil\n",
    "from io import open\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "# from keras.layers.core import Dense\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "from os.path import exists\n",
    "from pathlib import Path\n",
    "from os.path import exists as file_exists\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import psutil\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, accuracy_score, homogeneity_score\n",
    "from sklearn.metrics import completeness_score\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import backend as K\n",
    "import csv\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "# from mpl_toolkits import mplot3d\n",
    "from numpy.linalg import eig\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from sklearn.datasets import make_s_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sequence(header, seq):\n",
    "    \"\"\"\n",
    "    Adapted from VAMB: https://github.com/RasmussenLab\n",
    "\n",
    "    Check that there're no invalid characters or bad format\n",
    "    in the file.\n",
    "\n",
    "    Note: The GAPS ('-') that are introduced from alignment\n",
    "    are considered valid characters.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(header) > 0 and (header[0] in ('>', '#') or header[0].isspace()):\n",
    "        raise ValueError('Bad character in sequence header')\n",
    "    if '\\t' in header:\n",
    "        raise ValueError('tab included in header')\n",
    "\n",
    "    basemask = bytearray.maketrans(b'acgtuUswkmyrbdhvnSWKMYRBDHV-',\n",
    "                                   b'ACGTTTNNNNNNNNNNNNNNNNNNNNNN')\n",
    "\n",
    "    masked = seq.translate(basemask, b' \\t\\n\\r')\n",
    "    stripped = masked.translate(None, b'ACGTN')\n",
    "    if len(stripped) > 0:\n",
    "        bad_character = chr(stripped[0])\n",
    "        msg = \"Invalid DNA byte in sequence {}: '{}'\"\n",
    "        raise ValueError(msg.format(header, bad_character))\n",
    "    return masked\n",
    "\n",
    "def get_class_ranges(df):\n",
    "    class_ranges = {}\n",
    "    labels = df['cluster_id'].unique()\n",
    "    for label in labels:\n",
    "        indices = df.index[df['cluster_id'] == label].tolist()\n",
    "        start_idx = indices[0]\n",
    "        end_idx = indices[-1]\n",
    "        class_ranges[label] = (start_idx, end_idx)\n",
    "    return class_ranges\n",
    "\n",
    "def SummaryFasta(fname, GT_file=None):\n",
    "    lines = list()\n",
    "    seq_id = \"\"\n",
    "    names, lengths = [], []\n",
    "    ground_truth = None\n",
    "    cluster_dis = None\n",
    "    class_indices = {}\n",
    "\n",
    "    if GT_file:\n",
    "        ground_truth = []\n",
    "        df = pd.read_csv(GT_file, sep='\\t')\n",
    "        print(df)\n",
    "        GT_dict = dict(zip(df.sequence_id, df.cluster_id))\n",
    "        cluster_dis = df['cluster_id'].value_counts().to_dict()\n",
    "\n",
    "    for line in open(fname, \"rb\"):\n",
    "\n",
    "        if line.startswith(b'#'):\n",
    "            pass\n",
    "\n",
    "        elif line.startswith(b'>'):\n",
    "            if seq_id != \"\":\n",
    "                seq = bytearray().join(lines)\n",
    "\n",
    "                if (GT_file and not seq_id in GT_dict):\n",
    "                    raise ValueError('Check GT for sequence {}'.format(seq_id))\n",
    "\n",
    "                seq = check_sequence(seq_id, seq)\n",
    "                names.append(seq_id)\n",
    "                lengths.append(len(seq))\n",
    "\n",
    "                if GT_file:\n",
    "                    ground_truth.append(GT_dict[seq_id])\n",
    "                    if GT_dict[seq_id] not in class_indices:\n",
    "                        class_indices[GT_dict[seq_id]] = []\n",
    "                    class_indices[GT_dict[seq_id]].append(len(names) - 1)\n",
    "\n",
    "                lines = []\n",
    "                seq_id = line[1:-1].decode()  # Modify this according to your labels.\n",
    "\n",
    "            seq_id = line[1:-1].decode()\n",
    "\n",
    "        else:\n",
    "            lines += [line.strip()]\n",
    "\n",
    "    if (GT_file and not seq_id in GT_dict):\n",
    "        raise ValueError('Check GT for sequence {}'.format(seq_id))\n",
    "\n",
    "    seq = bytearray().join(lines)\n",
    "    seq = check_sequence(seq_id, seq)\n",
    "    names.append(seq_id)\n",
    "    lengths.append(len(seq))\n",
    "\n",
    "    if GT_file:\n",
    "        ground_truth.append(GT_dict[seq_id])\n",
    "        if GT_dict[seq_id] not in class_indices:\n",
    "            class_indices[GT_dict[seq_id]] = []\n",
    "        class_indices[GT_dict[seq_id]].append(len(names) - 1)\n",
    "\n",
    "    class_ranges =get_class_ranges(df)\n",
    "\n",
    "    return names, lengths, ground_truth, cluster_dis, class_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Extraction: Kmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nucleotide_sequences(file):\n",
    "    if os.path.exists(file) == False:\n",
    "        print('Error: file %s does not exist.' % file)\n",
    "        sys.exit(1)\n",
    "    with open(file) as f:\n",
    "        records = f.read()\n",
    "    if re.search('>', records) == None:\n",
    "        print('Error: the input file %s seems not in FASTA format!' % file)\n",
    "        sys.exit(1)\n",
    "    records = records.split('>')[1:]\n",
    "    fasta_sequences = []\n",
    "    for fasta in records:\n",
    "        array = fasta.split('\\n')\n",
    "        header, sequence = array[0].split()[0], re.sub('[^ACGTU-]', '-', ''.join(array[1:]).upper())\n",
    "        header_array = header.split('|')\n",
    "        name = header_array[0]\n",
    "        label = header_array[1] if len(header_array) >= 2 else '0'\n",
    "        label_train = header_array[2] if len(header_array) >= 3 else 'training'\n",
    "        sequence = re.sub('U', 'T', sequence)\n",
    "        fasta_sequences.append([name, sequence, label, label_train])\n",
    "    return fasta_sequences\n",
    "\n",
    "def read_protein_sequences(file):\n",
    "    if os.path.exists(file) == False:\n",
    "        print('Error: file %s does not exist.' % file)\n",
    "        sys.exit(1)\n",
    "    with open(file) as f:\n",
    "        records = f.read()\n",
    "    if re.search('>', records) == None:\n",
    "        print('Error: the input file %s seems not in FASTA format!' % file)\n",
    "        sys.exit(1)\n",
    "    records = records.split('>')[1:]\n",
    "    fasta_sequences = []\n",
    "    for fasta in records:\n",
    "        array = fasta.split('\\n')\n",
    "        header, sequence = array[0].split()[0], re.sub('[^ACDEFGHIKLMNPQRSTVWY-]', '-', ''.join(array[1:]).upper())\n",
    "        header_array = header.split('|')\n",
    "        name = header_array[0]\n",
    "        label = header_array[1] if len(header_array) >= 1 else '0'\n",
    "        label_train = header_array[2] if len(header_array) >= 2 else 'training'\n",
    "        fasta_sequences.append([name, sequence, label, label_train])\n",
    "    return fasta_sequences\n",
    "\n",
    "def readFasta(file):\n",
    "    if os.path.exists(file) == False:\n",
    "        print('Error: \"' + file + '\" does not exist.')\n",
    "        sys.exit(1)\n",
    "\n",
    "    with open(file) as f:\n",
    "        records = f.read()\n",
    "\n",
    "    if re.search('>', records) == None:\n",
    "        print('The input file seems not in fasta format.')\n",
    "        sys.exit(1)\n",
    "\n",
    "    records = records.split('>')[1:]\n",
    "    myFasta = []\n",
    "    for fasta in records:\n",
    "        array = fasta.split('\\n')\n",
    "        name, sequence = array[0].split()[0], re.sub('[^ARNDCQEGHILKMFPSTWYV-]', '-', ''.join(array[1:]).upper())\n",
    "        myFasta.append([name, sequence])\n",
    "    return myFasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Kmer Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def write_to_svm(encodings, file):\n",
    "    with open(file, 'w') as f:\n",
    "        for line in encodings[1:]:\n",
    "            line = line[1:]\n",
    "            f.write('%s' % line[0])\n",
    "            for i in range(1, len(line)):\n",
    "                f.write('  %d:%s' % (i, line[i]))\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "def write_to_tsv(encodings, file):\n",
    "    with open(file, 'w') as f:\n",
    "        for line in encodings[1:]:\n",
    "            line = line[1:]\n",
    "            f.write('%s' % line[0])\n",
    "            for i in range(1, len(line)):\n",
    "                f.write('\\t%s' % line[i])\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "def write_to_tsv_1(encodings, file):\n",
    "    with open(file, 'w') as f:\n",
    "        for line in encodings:\n",
    "            f.write('%s' % line[0])\n",
    "            for i in range(2, len(line)):\n",
    "                f.write('\\t%s' % line[i])\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "def write_to_csv(encodings, file):\n",
    "    with open(file, 'w') as f:\n",
    "        for line in encodings[1:]:\n",
    "            line = line[1:]\n",
    "            f.write('%s' % line[0])\n",
    "            for i in range(1, len(line)):\n",
    "                f.write(',%s' % line[i])\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "def write_to_weka(encodings, file):\n",
    "    with open('%s.weka' % file, 'w') as f:\n",
    "        f.write('@relation descriptor\\n\\n')\n",
    "        for i in range(1, len(encodings[0][2:]) + 1):\n",
    "            f.write('@attribute f.%d numeric\\n' % i)\n",
    "        f.write('@attribute play {yes, no}\\n\\n')\n",
    "        f.write('@data\\n')\n",
    "        for line in encodings[1:]:\n",
    "            line = line[1:]\n",
    "            for fea in line[1:]:\n",
    "                f.write('%s,' % fea)\n",
    "            if line[0] == '1':\n",
    "                f.write('yes\\n')\n",
    "            else:\n",
    "                f.write('no\\n')\n",
    "\n",
    "\n",
    "def save_file(encodings, format='svm', file='encodings.txt'):\n",
    "    if encodings == 0:\n",
    "        with open(file, 'w') as f:\n",
    "            f.write('An error encountered.')\n",
    "    else:\n",
    "        if format == 'svm':\n",
    "            write_to_svm(encodings, file)\n",
    "        if format == 'tsv':\n",
    "            write_to_tsv(encodings, file)\n",
    "        if format == 'csv':\n",
    "            write_to_csv(encodings, file)\n",
    "        if format == 'weka':\n",
    "            write_to_weka(encodings, file)\n",
    "        if format == 'tsv_1':\n",
    "            write_to_tsv_1(encodings, file)\n",
    "\n",
    "\n",
    "def save_cluster_result(cluster, e, file='Clusters.txt'):\n",
    "    with open(file, 'w') as f:\n",
    "        if cluster == 0:\n",
    "            f.write(str(e))\n",
    "        else:\n",
    "            myCluster = np.array(cluster)\n",
    "            df = pd.DataFrame({'name': myCluster[:, 0], 'cluster': myCluster[:, 1]})\n",
    "            mySet = set(np.array(df.cluster).tolist())\n",
    "            f.write('# The sample/feature can be clustered into %d clusters:\\n' % len(mySet))\n",
    "            for l in sorted(mySet):\n",
    "                newData = np.array(df.loc[df.loc[:, \"cluster\"] == l, :].name)\n",
    "                f.write('Cluster_%s:\\t' % l)\n",
    "                for i in newData:\n",
    "                    f.write(i + '\\t')\n",
    "                f.write('\\n')\n",
    "            f.write('\\n==============================================================\\n')\n",
    "\n",
    "            f.write('Protein/Feature\\tcluster\\n')\n",
    "            for i in cluster:\n",
    "                f.write(i[0] + '\\t' + str(i[1]) + '\\n')\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_FS_result(feature, e, method, file='featureRank.txt'):\n",
    "    with open(file, 'w') as f:\n",
    "        if feature == 0:\n",
    "            f.write(str(e))\n",
    "        else:\n",
    "            f.write('# Feature selection method: %s\\n' % method)\n",
    "            f.write(\n",
    "                '# The features were ranked according to their importance, the topper the more important the feature is\\n');\n",
    "            f.write('=======================\\n')\n",
    "            for i in feature:\n",
    "                f.write(i[0] + '\\t' + str(i[1]) + '\\n')\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_reduction_result(reduced_data, file='dimension_reduction.txt'):\n",
    "    with open(file, 'w') as f:\n",
    "        f.write('sample')\n",
    "        for i in range(1, len(reduced_data[0])):\n",
    "            f.write('\\tpc.' + str(i))\n",
    "        f.write('\\n')\n",
    "        for i in reduced_data:\n",
    "            f.write(i[0])\n",
    "            for j in range(1, len(i)):\n",
    "                f.write('\\t' + str(i[j]))\n",
    "            f.write('\\n')\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_CV_result_binary(data, out, info=None):\n",
    "    with open(out, 'w') as f:\n",
    "        if info:\n",
    "            f.write('%s\\n' % info)\n",
    "        for i in range(len(data)):\n",
    "            f.write('# result for fold %d\\n' %(i + 1))\n",
    "            for j in range(len(data[i])):\n",
    "                f.write('%d\\t%s\\n' % (data[i][j][0], data[i][j][2]))\n",
    "    return None\n",
    "\n",
    "def save_CV_result(data, classes, out, info=None):\n",
    "    with open(out, 'w') as f:\n",
    "        if info:\n",
    "            f.write('%s\\n' % info)\n",
    "        for i in range(len(data)):\n",
    "            f.write('result for fold %d\\n' %(i + 1))\n",
    "            f.write('label')\n",
    "            for k in classes:\n",
    "                f.write('\\t%s' %k)\n",
    "            f.write('\\n')\n",
    "            for j in range(len(data[i])):\n",
    "                f.write('%d' % data[i][j][0])\n",
    "                for k in range(1, len(data[i][j])):\n",
    "                    f.write('\\t%s' %data[i][j][k])\n",
    "                f.write('\\n')\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_IND_result_binary(data, out, info=None):\n",
    "    with open(out, 'w') as f:\n",
    "        if info:\n",
    "            f.write('%s\\n' % info)\n",
    "        for i in data:\n",
    "            f.write('%d\\t%s\\n' % (i[0], i[2]))\n",
    "    return None\n",
    "\n",
    "def save_IND_result(data, classes, out, info=None):\n",
    "    with open(out, 'w') as f:\n",
    "        if info:\n",
    "            f.write('%s\\n' % info)\n",
    "        f.write('label')\n",
    "        for k in classes:\n",
    "            f.write('\\t%s' % k)\n",
    "        f.write('\\n')\n",
    "        for i in data:\n",
    "            f.write('%d' %i[0])\n",
    "            for j in range(1, len(i)):\n",
    "                f.write('\\t%s' %i[j])\n",
    "            f.write('\\n')\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_prediction_metrics_ind(m_dict, out):\n",
    "    with open(out, 'w') as f:\n",
    "        f.write('#')\n",
    "        for key in m_dict:\n",
    "            f.write('\\t%s' %key)\n",
    "        f.write('\\n')\n",
    "        f.write('Indep')\n",
    "        for key in m_dict:\n",
    "            f.write('\\t%s' %m_dict[key])\n",
    "        f.write('\\n')\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_prediction_metrics_ind_muti(m_dict, classes, out):\n",
    "    with open(out, 'w') as f:\n",
    "        f.write('#')\n",
    "        for c in classes:\n",
    "            f.write('\\tclass_%s_acc' %c)\n",
    "        f.write('\\n')\n",
    "        f.write('Indep')\n",
    "        for c in classes:\n",
    "            f.write('\\t%s' % m_dict[c])\n",
    "        f.write('\\n')\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_prediction_metrics_cv(m_list, out):\n",
    "    with open(out, 'w') as f:\n",
    "        f.write('Fold')\n",
    "        for key in m_list[0]:\n",
    "            f.write('\\t%s' %key)\n",
    "        f.write('\\n')\n",
    "        for i in range(len(m_list)):\n",
    "            f.write('%d' %(i + 1))\n",
    "            for key in m_list[i]:\n",
    "                f.write('\\t%s' %m_list[i][key])\n",
    "            f.write('\\n')\n",
    "    return None\n",
    "\n",
    "def save_prediction_metrics_2_classes(m_dict, out):\n",
    "    with open(out, 'w') as f:\n",
    "        f.write('#')\n",
    "        for m in ['Sensitivity', 'Specificity', 'Accuracy', 'MCC', 'Recall', 'Precision', 'F1-score']:\n",
    "            f.write('\\t%s' %m)\n",
    "        f.write('\\n')\n",
    "        for key in m_dict:\n",
    "            f.write('%s' %key)\n",
    "            for m in ['Sensitivity', 'Specificity', 'Accuracy', 'MCC', 'Recall', 'Precision', 'F1-score']:\n",
    "                f.write('\\t%.3f' %m_dict[key][m])\n",
    "            f.write('\\n')\n",
    "    return None\n",
    "\n",
    "def save_prediction_metrics_cv_muti(m_list, classes, out):\n",
    "    with open(out, 'w') as f:\n",
    "        f.write('Fold')\n",
    "        for c in classes:\n",
    "            f.write('\\tclass_%s_acc' %c)\n",
    "        f.write('\\n')\n",
    "        for fold in range(len(m_list)):\n",
    "            f.write('fold_%s' %(fold + 1))\n",
    "            for c in classes:\n",
    "                f.write('\\t%s' %m_list[fold][c])\n",
    "            f.write('\\n')\n",
    "    return None\n",
    "\n",
    "def save_prediction_metrics_muti_V2(muti_record_metrics, out):\n",
    "    with open(out, 'w') as f:\n",
    "        f.write('#\\tCV_accuracy\\tIND_accuracy\\n')\n",
    "        for key in muti_record_metrics:\n",
    "            f.write('%s\\t%.4f\\t%.4f\\n' %(key, muti_record_metrics[key][0], muti_record_metrics[key][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Generate K-mer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def kmerArray(sequence, k):\n",
    "    kmer = []\n",
    "    for i in range(len(sequence) - k + 1):\n",
    "        kmer.append(sequence[i:i + k])\n",
    "    return kmer\n",
    "\n",
    "def Kmer(fastas, k=2, type=\"DNA\", upto=False, normalize=True, **kw):\n",
    "    encoding = []\n",
    "    lK = []\n",
    "    header = ['#', 'label']\n",
    "    NA = 'ACGT' if type in (\"DNA\", 'RNA') else 'ACDEFGHIKLMNPQRSTVWY'\n",
    "\n",
    "    if k < 1:\n",
    "        print('Error: the k-mer value should be larger than 0.')\n",
    "        return 0\n",
    "\n",
    "    if upto:\n",
    "        for tmpK in range(1, k + 1):\n",
    "            for kmer in itertools.product(NA, repeat=tmpK):\n",
    "                header.append(''.join(kmer))\n",
    "        encoding.append(header)\n",
    "        for i in fastas:\n",
    "            name, sequence, label = i[0], re.sub('-', '', i[1]), i[2]\n",
    "            count = Counter()\n",
    "            for tmpK in range(1, k + 1):\n",
    "                kmers = kmerArray(sequence, tmpK)\n",
    "                count.update(kmers)\n",
    "                if normalize:\n",
    "                    for key in count:\n",
    "                        if len(key) == tmpK:\n",
    "                            count[key] = count[key] / len(kmers)\n",
    "            lK.append(kmers)\n",
    "            code = [name, label]\n",
    "            for j in range(2, len(header)):\n",
    "                code.append(count[header[j]] if header[j] in count else 0)\n",
    "            encoding.append(code)\n",
    "    else:\n",
    "        for kmer in itertools.product(NA, repeat=k):\n",
    "            header.append(''.join(kmer))\n",
    "        encoding.append(header)\n",
    "\n",
    "        for i in fastas:\n",
    "            name, sequence, label = i[0], re.sub('-', '', i[1]), i[2]\n",
    "            kmers = kmerArray(sequence, k)\n",
    "            count = Counter()\n",
    "            count.update(kmers)\n",
    "            if normalize:\n",
    "                for key in count:\n",
    "                    count[key] = count[key] / len(kmers)\n",
    "\n",
    "            code = [name, label]\n",
    "            for j in range(2, len(header)):\n",
    "                code.append(count[header[j]] if header[j] in count else 0)\n",
    "            encoding.append(code)\n",
    "\n",
    "    dict = {'feature': header[2:]}\n",
    "    df = pd.DataFrame(dict)\n",
    "    df.to_csv('Feature.csv')\n",
    "    return encoding\n",
    "\n",
    "def preprocess(f):\n",
    "    Feature_app1 = []\n",
    "    for i in f:\n",
    "        L = i.strip().split(':')\n",
    "        Feature_app = [str(L[j]).split()[0] for j in range(1, len(L))]\n",
    "        Feature_app1.append(Feature_app)\n",
    "    Feature_app2 = np.array(Feature_app1).astype(float)\n",
    "    return Feature_app2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reduce Feature Dimension: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def run_pca(X,n_components):\n",
    "    # Step 1: StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_scale = sc.fit_transform(X)\n",
    "    \n",
    "    # Step 2: PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_scale_pca = pca.fit_transform(X_scale)\n",
    "  \n",
    "    # Step 3: Get components\n",
    "    n_pcs = pca.components_.shape[0]\n",
    "    print(\"Number of principal components:\", n_pcs)\n",
    "\n",
    "    # Step 4: Select components with explained variance ratio > 0.1\n",
    "    exp_var_pca = pca.explained_variance_ratio_\n",
    "    total_explained_variance = exp_var_pca.sum()  \n",
    "\n",
    "    return X_scale, X_scale_pca, pca.components_, exp_var_pca, total_explained_variance, pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create pattern for learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1: Generate synthetic data using make_blobs with a random number of clusters and standard deviation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Util function: writing training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort(sub_list):\n",
    " \n",
    "    # reverse = None (Sorts in Ascending order)\n",
    "    # key is set to sort using second element of\n",
    "    # sublist lambda has been used\n",
    "    return(sorted(sub_list, key = lambda x: x[0]))\n",
    "\n",
    "def write_files(paths, features, number_dimension, j, i,n):\n",
    "    dimension_list = []\n",
    "    #normalized to 0-1\n",
    "    for k in range(number_dimension):\n",
    "        X = features[:, k]\n",
    "        min_xvalue = min(X)\n",
    "        if min_xvalue < 0:\n",
    "            X = X + abs(min_xvalue)\n",
    "        max_xvalue = max(X)\n",
    "        X = X / abs(max_xvalue)\n",
    "        dimension_list.append(X)\n",
    "\n",
    "    number_point = len(dimension_list[0])\n",
    "    file_name = f\"train-cluster{j}-dataset{i}.txt\"\n",
    "    with open(f\"{paths}/{file_name}\", \"w\") as fout:\n",
    "        for k in range(number_point):\n",
    "            for l in range(number_dimension):\n",
    "                print(dimension_list[l][k], end=\" \", file=fout)\n",
    "            output_values = [0] * n\n",
    "            if 1 <= j <= n:\n",
    "                output_values[j - 1] = 0.5\n",
    "            print(\" \".join(map(str, output_values)), file=fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_guassian_make_bobs(start_gen_gaussian_train_data_set,end_gen_gaussian_train_data_set,num_real, start_cluster,max_number_of_cluster,min_no_point,max_no_point, dimension,min_std,max_std,n_real,paths):\n",
    "    \n",
    "    #Variable assignment    \n",
    "    start_number_data_set   = start_gen_gaussian_train_data_set\n",
    "    last_number_of_data_set = end_gen_gaussian_train_data_set\n",
    "    min_no_point  = min_no_point\n",
    "    max_no_point  = max_no_point\n",
    "    number_dimension = dimension\n",
    "\n",
    "\n",
    "    print(\"generate gaussian training data_real\")\n",
    "    print(\"from data set\", start_number_data_set, \"-\", last_number_of_data_set)\n",
    "    print(\"number dimension:\",number_dimension)\n",
    "\n",
    "    #----------------------------------------------------------------#\n",
    "    for j in range(start_cluster,max_number_of_cluster+1):\n",
    "        if j!=n_real: \n",
    "            for i in range(start_number_data_set,last_number_of_data_set+1):\n",
    "                number_of_center = j\n",
    "                number_point = random.randint(min_no_point, max_no_point)\n",
    "                stdx= random.uniform(min_std,max_std)\n",
    "                features, clusters, center = make_blobs(n_samples = number_point, \\\n",
    "                                                n_features = number_dimension, \\\n",
    "                                                centers = number_of_center,\\\n",
    "                                                cluster_std = stdx , shuffle = True, \\\n",
    "                                                return_centers = True)\n",
    "                write_files(paths,features,number_dimension,j,i,max_number_of_cluster)\n",
    "        else:\n",
    "            for i in range(start_number_data_set,last_number_of_data_set-num_real+1):\n",
    "                number_of_center = j\n",
    "                number_point = random.randint(min_no_point, max_no_point)\n",
    "                stdx= random.uniform(min_std,max_std)\n",
    "                features, clusters, center = make_blobs(n_samples = number_point, \\\n",
    "                                                n_features = number_dimension, \\\n",
    "                                                centers = number_of_center,\\\n",
    "                                                cluster_std = stdx , shuffle = True, \\\n",
    "                                                return_centers = True)\n",
    "                write_files(paths,features,number_dimension,j,i,max_number_of_cluster)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2: Generate patterns from dense regions using a random seed and nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_random_high_density_point(data, labels, class_range):\n",
    "    \"\"\"\n",
    "    Select a random point from the high-density region of each cluster.\n",
    "\n",
    "    :param data: Numpy array of shape (n_samples, n_features)\n",
    "    :param labels: Numpy array of shape (n_samples,), cluster labels for each sample\n",
    "    :param class_range: Dictionary mapping class names to tuples of index ranges\n",
    "    :return: List of random points from high-density regions, one for each cluster\n",
    "    \"\"\"\n",
    "    selected_points = []\n",
    "    centers = []\n",
    "    high_density_points = []\n",
    "    std_dev_c=[]\n",
    "    \n",
    "    for class_name, (start_idx, end_idx) in class_range.items():\n",
    "        # Extract points belonging to the current class based on the index range\n",
    "        cluster_points = data[start_idx:end_idx + 1]\n",
    "\n",
    "        # If the cluster has fewer than 2 points, just select the point(s) directly\n",
    "        if len(cluster_points) < 2:\n",
    "            selected_points.extend(cluster_points)\n",
    "            continue\n",
    "\n",
    "        # Estimate the density of points in the cluster\n",
    "        kde = gaussian_kde(cluster_points.T)\n",
    "        \n",
    "        # Evaluate the density at each point\n",
    "        densities = kde(cluster_points.T)\n",
    "        \n",
    "        # Get the indices of the high-density points\n",
    "        high_density_indices = np.where(densities > np.percentile(densities,85))[0]\n",
    "        \n",
    "        # Randomly select one point from the high-density region\n",
    "        selected_index = random.choice(high_density_indices)\n",
    "        selected_points.append(cluster_points[selected_index])\n",
    "\n",
    "        # Compute the center of high-density region\n",
    "        high_density_cluster_points = cluster_points[high_density_indices]\n",
    "        ######## this is true std of cluster or not \n",
    "        # Calculate and print standard deviation of high-density points\n",
    "        std_dev = np.std(high_density_cluster_points, axis=0)\n",
    "        # print(f'Standard deviation of high-density points for class {class_name}: {std_dev}')\n",
    "        std_dev_c.append(np.mean(std_dev))\n",
    "        # print(std_dev_c)\n",
    "        #####################\n",
    "        high_density_points.extend(high_density_cluster_points)\n",
    "        center = high_density_cluster_points.mean(axis=0)\n",
    "        centers.append(center)\n",
    "\n",
    "    # Convert high_density_points to numpy array\n",
    "    high_density_points = np.array(high_density_points)\n",
    "\n",
    "    # Convert selected_points and centers to numpy arrays\n",
    "    selected_points = np.array(selected_points)\n",
    "    centers = np.array(centers)\n",
    "    \n",
    "    return selected_points,std_dev_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_pick_and_find_nearby(X_normalized, class_ranges, selected_points,increase, mean_std_devs):\n",
    "    # For each cluster, select a random seed point and collect neighboring points within a\n",
    "    # radius defined by the cluster-wise mean standard deviation scaled by `increase`\n",
    "\n",
    "    random_points = {}\n",
    "    nearby_points_c = np.empty((0, X_normalized.shape[1]))\n",
    "    i = 0\n",
    "    \n",
    "    for class_label, (start_idx, end_idx) in class_ranges.items():\n",
    "        # 1. define radius\n",
    "        radius = increase*mean_std_devs[i] \n",
    "         \n",
    "        # 2. random point from selected points\n",
    "        random_point = selected_points[i]\n",
    "        random_points[class_label] = random_point\n",
    "   \n",
    "        # 3. find nearest distance\n",
    "        distances = np.linalg.norm(X_normalized - random_point, axis=1)\n",
    "        nearby_indices = np.where(distances < radius)[0]\n",
    "        nearby_points = X_normalized[nearby_indices]\n",
    "\n",
    "        # 4. Include the random point in the nearby points\n",
    "        if not np.any(np.all(nearby_points == random_point, axis=1)):\n",
    "            nearby_points = np.vstack((nearby_points, random_point))\n",
    "        \n",
    "        # 5. Concatenate nearest points\n",
    "        nearby_points_c = np.concatenate((nearby_points_c, nearby_points), axis=0)\n",
    "        i += 1\n",
    "        \n",
    "    return nearby_points_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_real(start_gen_real_train_data_set, end_gen_real_train_data_set,X_normalized, class_ranges,n_real,GT,increase,max_number_of_cluster,paths):\n",
    "  \n",
    "    start_number_data_set = start_gen_real_train_data_set\n",
    "    last_number_of_data_set = end_gen_real_train_data_set\n",
    "\n",
    "    print(\"Generate Real training data\")\n",
    "    print(f\"From dataset {start_number_data_set} - {last_number_of_data_set}\")\n",
    "    n_count=[]\n",
    "    std_dev_collect=[]\n",
    "\n",
    "    for i in range(start_number_data_set, last_number_of_data_set + 1):\n",
    "      selected_points,std_dev_c= select_random_high_density_point(X_normalized, GT, class_ranges)\n",
    "      nearby_points =random_pick_and_find_nearby(X_normalized, class_ranges, selected_points,increase,std_dev_c)\n",
    "      n_count.append(len(nearby_points))\n",
    "      std_dev_collect.append(std_dev_c)\n",
    "      write_files(paths, nearby_points, X_normalized.shape[1], n_real, i,max_number_of_cluster)\n",
    "\n",
    "    return n_count, std_dev_collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Combine Gaussian and KDE-based training samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "import ast\n",
    "\n",
    "def train_only_add_points_before_encode_data(start_add_point_train_data_set,end_add_point_train_data_set,start_cluster,max_number_of_cluster,max_no_point,number_dimension,paths):\n",
    "    total_cluster = max_number_of_cluster\n",
    "    add_x = 0.0\n",
    "    add_y = 0.0\n",
    "\n",
    "\n",
    "    bitlength = max_number_of_cluster\n",
    "    train_start_dataset = start_add_point_train_data_set\n",
    "    train_last_number_of_data_set=end_add_point_train_data_set\n",
    "\n",
    "    print(\"add train - test point\")\n",
    "    print(\"number of encode train data in each cluster:\", \\\n",
    "        train_last_number_of_data_set)\n",
    "\n",
    "    #------------- find number of added lines in train data set -------------------\n",
    "    max_line = 0\n",
    "    min_line = 100000\n",
    "\n",
    "    for j in range(start_cluster,max_number_of_cluster+1):\n",
    "        for i in range(train_start_dataset, train_last_number_of_data_set+1):\n",
    "            input_file_name = f\"{paths}/train-cluster\" + str(j) + \"-dataset\" + str(i) + \".txt\"\n",
    "            with open(input_file_name,'r') as data_file:\n",
    "                number_line = 0\n",
    "                for line in data_file:\n",
    "                    data = line.split()\n",
    "                    size = len(data)\n",
    "                    if size > 0:\n",
    "                        number_line = number_line + 1\n",
    "                    else:\n",
    "                        print(\"empty line: remove\", number_line, \" line from file\") \n",
    "    #            number_line = len(data_file.readlines())\n",
    "            data_file.close()\n",
    "            \n",
    "            if max_line < number_line:\n",
    "                max_line = number_line\n",
    "            if min_line > number_line:\n",
    "                min_line = number_line\n",
    "            \n",
    "    train_max_point = max_line\n",
    "    train_min_point = min_line\n",
    "    max_point = train_max_point\n",
    "    if max_point < max_no_point:\n",
    "        max_point = max_no_point \n",
    "\n",
    "    print(\"train max point: \", max_point, \" train min point: \", train_min_point)\n",
    "\n",
    "    #------------------------ train data --------------------------------------------    \n",
    "    print(\"add train point\")\n",
    "    train_data_set = []\n",
    "\n",
    "    for j in range(start_cluster,max_number_of_cluster+1):\n",
    "        for i in range(train_start_dataset, train_last_number_of_data_set+1):\n",
    "            input_file_name = f\"{paths}/train-cluster\" + str(j) + \"-dataset\" + str(i) + \".txt\"\n",
    "            count_line = 0\n",
    "            with open(input_file_name,'r') as data_file:\n",
    "                for line in data_file:\n",
    "                    data = line.split()\n",
    "                    size = len(data)\n",
    "                    if size > 0:\n",
    "                        count_line = count_line + 1\n",
    "                    else:\n",
    "                        print(\"empty line: remove\", count_line, \" line from file\")      \n",
    "            data_file.close()\n",
    "\n",
    "            if count_line < max_point:\n",
    "                add_pattern = max_point - count_line\n",
    "                train_data_set = []\n",
    "                with open(input_file_name,'r') as data_file:\n",
    "                    for line in data_file:\n",
    "                        data = line.split()\n",
    "                        size = len(data)\n",
    "                        if size > 0:\n",
    "                            cluster_name_bitpattern = []\n",
    "                            for k in range(number_dimension):\n",
    "                                x = float(data[k])\n",
    "                                cluster_name_bitpattern.append(x)\n",
    "                            target = []\n",
    "                            for k in range(bitlength):\n",
    "                                bitnumber = ast.literal_eval(data[k+number_dimension])\n",
    "                                cluster_name_bitpattern.append(bitnumber)\n",
    "                                target.append(bitnumber)\n",
    "                            temp_list = copy.deepcopy(cluster_name_bitpattern)\n",
    "                            train_data_set.append(temp_list)\n",
    "                        else:\n",
    "                            print(\"last line is empty: delete empty line\")\n",
    "                data_file.close()\n",
    "\n",
    "                with open(input_file_name,'a') as data_file:\n",
    "                    for k in range(add_pattern):\n",
    "                        index = random.randint(0,count_line-1)\n",
    "                        for l in range(number_dimension):\n",
    "                            add_x = train_data_set[index][l]\n",
    "                            print(add_x, end = \" \", file = data_file)\n",
    "                        for l in range(bitlength-1):\n",
    "                            print(target[l], end = \" \", file = data_file)\n",
    "                        print(target[bitlength-1], file = data_file)\n",
    "                data_file.close()\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import backend as K\n",
    "import sys\n",
    "import csv\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy.linalg import eig\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "def Sort(sub_list):\n",
    " \n",
    "    # reverse = None (Sorts in Ascending order)\n",
    "    # key is set to sort using second element of\n",
    "    # sublist lambda has been used\n",
    "    return(sorted(sub_list, key = lambda x: x[0]))\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "def add_point(normalize_point_list, number_dimension, max_no_point):\n",
    "    add_normalize_point_list = copy.deepcopy(normalize_point_list)\n",
    "    number_add_point = max_no_point - len(normalize_point_list)\n",
    "    size_normalize_point_list = len(normalize_point_list)\n",
    "    if number_add_point > 0:\n",
    "        for i in range(number_add_point):\n",
    "            index = random.randint(0,size_normalize_point_list-1)\n",
    "            feature = []\n",
    "            feature = copy.deepcopy(normalize_point_list[index])\n",
    "            add_normalize_point_list.append(feature)\n",
    "    return add_normalize_point_list\n",
    "\n",
    "#---------------------------------------------------------------------#\n",
    "\n",
    "def prepare_test_data_add_point(input_file_name_ori,max_number_of_cluster,max_no_point,number_dimension,paths):\n",
    "    total_cluster = max_number_of_cluster\n",
    "\n",
    "    print(\"---- read test data and normalize each dimension\")\n",
    "    #bitlength = total_cluster.bit_length()\n",
    "    bitlength = max_number_of_cluster\n",
    "\n",
    "    test_data = []\n",
    "    test_target = []\n",
    "    temp_target_pattern = []\n",
    "\n",
    "    input_file_name =input_file_name_ori\n",
    "    print(\"\\ntest data file:\", input_file_name)\n",
    "    point_list = []\n",
    "    rows = []\n",
    "\n",
    "\n",
    "    with open(input_file_name,'r') as data_file:\n",
    "        for line in data_file:\n",
    "            # print(line)\n",
    "            data = line.split(\",\")\n",
    "    #         print(data)\n",
    "            size = len(data)\n",
    "            if data[0] != '\\n':\n",
    "                cluster_name_bitpattern = []\n",
    "                for k in range(number_dimension):\n",
    "    #                 print(data[k])\n",
    "                    x = float(data[k])\n",
    "                    # print(type(x))\n",
    "                    cluster_name_bitpattern.append(x)\n",
    "                temp_list = copy.deepcopy(cluster_name_bitpattern)    \n",
    "                point_list.append(temp_list)\n",
    "\n",
    "    data_file.close()\n",
    "\n",
    "    # print('cluster_name_bitpattern',cluster_name_bitpattern ) #encoding score \n",
    "\n",
    "\n",
    "    normalize_point_list = []\n",
    "    number_point = len(point_list)\n",
    "    features = []\n",
    "    features = copy.deepcopy(point_list)\n",
    "\n",
    "    dimension_list = []\n",
    "\n",
    "    for k in range(number_dimension):\n",
    "        X = []\n",
    "        for i in range(number_point):\n",
    "            a = float(features[i][k])\n",
    "            X.append(a)\n",
    "        min_xvalue = min(X)\n",
    "        if min_xvalue < 0:\n",
    "            for i in range(number_point):\n",
    "                X[i] = X[i] + abs(min_xvalue)\n",
    "        max_xvalue = max(X)\n",
    "        for i in range(number_point):\n",
    "            X[i] = X[i]/abs(max_xvalue)\n",
    "        dimension_list.append(X)\n",
    "\n",
    "    for i in range(number_point):\n",
    "        features = []\n",
    "        for k in range(number_dimension):\n",
    "            a = dimension_list[k][i]\n",
    "            features.append(a)\n",
    "        normalize_point_list.append(features)\n",
    "\n",
    "    add_normalize_point_list = add_point(normalize_point_list, number_dimension, \\\n",
    "                                        max_no_point)\n",
    "\n",
    "    fout = open(f'{paths}/test-data-normalize.txt', 'w')\n",
    "    for i in range(len(add_normalize_point_list)):\n",
    "        for j in range(number_dimension):\n",
    "            print(add_normalize_point_list[i][j], end = \" \", file = fout)\n",
    "        for j in range(bitlength-1):\n",
    "            print(\"0.0\", end = \" \", file = fout)\n",
    "        print(\"0.0\", file = fout)\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Combine all pattern together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import backend as K\n",
    "import sys\n",
    "import csv\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy.linalg import eig\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "def Sort(sub_list):\n",
    " \n",
    "    # reverse = None (Sorts in Ascending order)\n",
    "    # key is set to sort using second element of\n",
    "    # sublist lambda has been used\n",
    "    return(sorted(sub_list, key = lambda x: x[0]))\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "def encode(encode_train_data,paths):\n",
    "    X = copy.deepcopy(encode_train_data)\n",
    "    # print(X[0])\n",
    "    X = np.array(X)\n",
    "    Y = copy.deepcopy(encode_train_data)\n",
    "    Y = np.array(Y)\n",
    "    input_dim = len(encode_train_data[0]) #--- get input dim from 1st pattern ---\n",
    "    no_input = input_dim\n",
    "    no_hidden = 313\n",
    "    no_output = input_dim\n",
    "    no_epoch = 4000\n",
    "\n",
    "    print(\"number of dimensions of encoded vector: \", no_hidden)\n",
    "    print(\"number of dimensions of input: \", input_dim)\n",
    "    print(\"number of training patterns: \", len(encode_train_data))\n",
    "    print(\"number of epochs: \", no_epoch)\n",
    "    print(\"in encode\")\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    model.add(Dense(no_hidden, input_dim = no_input, activation='sigmoid')) \n",
    "    model.add(Dense(no_output, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', \\\n",
    "                  metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "#                    metrics=[keras.metrics.BinaryAccuracy()])\n",
    "    model.fit(X, Y, epochs=no_epoch, verbose = 0)\n",
    "\n",
    "    ynew = model.predict(X,verbose=0)\n",
    "    model.save(f'{paths}/model1')\n",
    "\n",
    "\n",
    "#-------------- use this instructions to get hidden layer value ----------\n",
    "\n",
    "    get_0_layer_output = K.function([model.layers[0].input],[model.layers[0].output])\n",
    "    layer_encode_output = get_0_layer_output(X)[0]\n",
    "\n",
    "\n",
    "    get_1_layer_output = K.function([model.layers[0].input],[model.layers[1].output])\n",
    "    layer_output = get_1_layer_output(X)[0]\n",
    "\n",
    "\n",
    "    scores = model.evaluate(X,Y,verbose=0)\n",
    "\n",
    "    return layer_encode_output, scores[0], scores[1], ynew[0]\n",
    "\n",
    "\n",
    "def encode_train_test_pattern(start_encode_train_data_set, end_encode_train_data_set,start_cluster,max_number_of_cluster,number_dimension,paths):\n",
    "    total_cluster = max_number_of_cluster\n",
    "\n",
    "    print(\"encode\")\n",
    "    print(\"number of encode pattern:\", start_encode_train_data_set, \"-\", \\\n",
    "        end_encode_train_data_set )\n",
    "    #bitlength = total_cluster.bit_length()\n",
    "\n",
    "        \n",
    "    output_file_name = f\"{paths}/encode-all-cluster.txt\"\n",
    "    print(output_file_name)\n",
    "    fout = open(output_file_name, \"w\")\n",
    "    train_data = []\n",
    "    target_pattern = []\n",
    "    temp_target_pattern = []\n",
    "    \n",
    "    type_arrangement = 2 #---- 1 = \"dist from org\", 2 = \"arrange_by_dim\" ----\n",
    "\n",
    "    if type_arrangement == 1:\n",
    "        print(\"----- sort-by-dist dim: \")\n",
    "    if type_arrangement == 2:\n",
    "        print(\"----- sort-by-dim dim: \")\n",
    "\n",
    "    input_file_name = f\"{paths}/train-cluster{start_cluster}-dataset1.txt\"\n",
    "    with open(input_file_name,'r') as data_file:\n",
    "        for line in data_file:\n",
    "            data = line.split()\n",
    "            size = len(data)\n",
    "            bitlength = size - number_dimension\n",
    "            break\n",
    "    data_file.close()\n",
    "    print(\"bitlength\", bitlength)\n",
    "\n",
    "    for j in range(start_cluster,max_number_of_cluster+2):\n",
    "        for i in range(start_encode_train_data_set, end_encode_train_data_set+1):\n",
    "            if j == max_number_of_cluster+1:\n",
    "                input_file_name = f\"{paths}/test-data-normalize.txt\"\n",
    "            else:\n",
    "                input_file_name = f\"{paths}/train-cluster\" + str(j) + \"-dataset\" + str(i) + \\\n",
    "                                \".txt\"\n",
    "            point_list = [] \n",
    "            with open(input_file_name,'r') as data_file:\n",
    "                for line in data_file:\n",
    "                    data = line.split()\n",
    "                    size = len(data)\n",
    "                    cluster_name_bitpattern = []\n",
    "                    cluster_name_bitpattern.clear()\n",
    "                    for k in range(number_dimension):\n",
    "                        x = float(data[k])\n",
    "                        # print(type(x))\n",
    "                        cluster_name_bitpattern.append(x)\n",
    "                    temp_target_pattern = []\n",
    "                    for k in range(bitlength):\n",
    "                        bitnumber = float(data[k+number_dimension])\n",
    "                        cluster_name_bitpattern.append(bitnumber)\n",
    "                        temp_target_pattern.append(bitnumber)\n",
    "                    temp_list = copy.deepcopy(cluster_name_bitpattern)    \n",
    "                    point_list.append(temp_list)\n",
    "            temp = copy.deepcopy(temp_target_pattern)\n",
    "            target_pattern.append(temp)\n",
    "        \n",
    "            data_file.close()\n",
    "            \n",
    "            input_from_coordinate = []\n",
    "            dist_from_org = []\n",
    "            dist_histogram = []\n",
    "\n",
    "            if type_arrangement == 1:\n",
    "                size_point_list = len(point_list)\n",
    "                for k in range(size_point_list):\n",
    "                    dist = 0\n",
    "                    for l in range(number_dimension):\n",
    "                        dist = dist + point_list[k][l]**2\n",
    "                    dist = math.sqrt(dist)\n",
    "                    temp_dist = []\n",
    "                    temp_dist.append(dist)\n",
    "                    for l in range(number_dimension):\n",
    "                        temp_dist.append(point_list[k][l])\n",
    "                    dist_from_org.append(temp_dist)\n",
    "\n",
    "                sort_dist_from_org = []\n",
    "                sort_dist_from_org = Sort(dist_from_org)\n",
    "\n",
    "                for k in range(size_point_list):\n",
    "                    for l in range(number_dimension):\n",
    "                        x = sort_dist_from_org[k][1]\n",
    "                        # print(x)\n",
    "                        # print('xxx 250')\n",
    "                        input_from_coordinate.append(x)\n",
    "\n",
    "                temp_pattern = copy.deepcopy(input_from_coordinate)\n",
    "                print(temp_pattern)\n",
    "                train_data.append(temp_pattern)\n",
    "\n",
    "            if type_arrangement == 2:\n",
    "                input_from_coordinate = []\n",
    "                temp_pattern = []\n",
    "                size_point_list = len(point_list)\n",
    "                for l in range(number_dimension):\n",
    "                    x_dimension_list = []\n",
    "                    for k in range(size_point_list):\n",
    "                        x = point_list[k][l]\n",
    "                        x_dimension_list.append(x)\n",
    "                    x_dimension_list.sort()\n",
    "                    input_from_coordinate = input_from_coordinate + x_dimension_list\n",
    "                # print(input_from_coordinate)     \n",
    "                temp_pattern = copy.deepcopy(input_from_coordinate)\n",
    "                train_data.append(temp_pattern)\n",
    "            if j == max_number_of_cluster+1:\n",
    "                break\n",
    "\n",
    "    print(type(train_data))\n",
    "    train_data = np.array(train_data)\n",
    "\n",
    "    do_encode =0 \n",
    "    \n",
    "    if  do_encode ==0:\n",
    "        encode_output = copy.deepcopy(train_data)\n",
    "    if  do_encode ==1:\n",
    "        encode_output, loss, error, output_y = encode(train_data,paths)\n",
    "\n",
    "        print(\"-------- encode output\")\n",
    "        print(\"loss: \", loss)\n",
    "        print(\"rms error\", error)\n",
    "    no_of_encoded_pattern = len(encode_output)\n",
    "    dim_encode_pattern = len(encode_output[0]) #--- get dim of each ecodeed pattern ---\n",
    "    print(\"number of encoded patterns:\", no_of_encoded_pattern)\n",
    "\n",
    "    for i in range(no_of_encoded_pattern):\n",
    "        cluster_no = i // end_encode_train_data_set + 1\n",
    "        dataset_no = i % end_encode_train_data_set + 1\n",
    "        print(cluster_no, \" \", dataset_no, \" \", end = \" \", file = fout)\n",
    "        for k in range(dim_encode_pattern):\n",
    "            print(encode_output[i][k], end = \" \", file = fout)\n",
    "        for l in range(bitlength-1):\n",
    "            print(target_pattern[i][l], end = \" \", file = fout)\n",
    "        print(target_pattern[i][bitlength-1], file = fout)\n",
    "\n",
    "\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "# from keras.layers.core import Dense\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "from os.path import exists\n",
    "from pathlib import Path\n",
    "from os.path import exists as file_exists\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import psutil\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, accuracy_score, homogeneity_score\n",
    "from sklearn.metrics import completeness_score\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import v_measure_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "def adjust_predict_output(predict_output_test, test_target, print_adjust = 'no', \\\n",
    "                          print_wrong_prediction = 'no', target_defined = 'yes'):\n",
    "    dim = len(predict_output_test[0])\n",
    "    number_test_pattern = len(predict_output_test)\n",
    "    all_adjust_predict = []\n",
    "\n",
    "#--------- find max value, reset max value to 0.5 and the rest to 0.0 -------  \n",
    "    \n",
    "    for i in range(number_test_pattern):\n",
    "        adjust_predict = []\n",
    "        max_value = predict_output_test[i][0]\n",
    "        for j in range(dim):\n",
    "            if max_value < predict_output_test[i][j]:\n",
    "                max_value = predict_output_test[i][j]\n",
    "\n",
    "        for j in range(dim):\n",
    "            if predict_output_test[i][j] < max_value:\n",
    "                adjust_predict.append(0.0)\n",
    "            else:\n",
    "                adjust_predict.append(0.5)\n",
    "        temp_list = copy.deepcopy(adjust_predict)\n",
    "        all_adjust_predict.append(temp_list)\n",
    "        \n",
    "    number_test_set = len(test_target)\n",
    "    # if print_adjust == 'yes':\n",
    "    #     for i in range(number_test_set):\n",
    "    #         print(\"\\nPredicted = %s\" % (predict_output_test[i]), \"\\ntarget = %s\" % \\\n",
    "    #               (test_target[i]))\n",
    "    #         print(\"adjust Predicted = %s\" % (all_adjust_predict[i]), \"\\ntarget = %s\" % \\\n",
    "    #               (test_target[i]))\n",
    "    #         print(\" \")\n",
    "\n",
    "    dim = len(test_target[0])\n",
    "    count_same_answer = 0\n",
    "    wrong_predict = []\n",
    "\n",
    "#------- compute accuracy of each cluster and total accuracy ---------------- \n",
    "\n",
    "    pattern_cluster = []\n",
    "    accuracy_cluster = []\n",
    "    \n",
    "    for i in range(dim):\n",
    "        pattern_cluster.append(0)\n",
    "        accuracy_cluster.append(0)\n",
    "\n",
    "    if target_defined == 'yes':   \n",
    "        for i in range(number_test_set):\n",
    "            for k in range(dim):\n",
    "                if test_target[i][k] == 0.5: #------ cannot use if test target = 0.0\n",
    "                    cluster_index = k\n",
    "                    break\n",
    "            pattern_cluster[cluster_index] = pattern_cluster[cluster_index] + 1\n",
    "            print(pattern_cluster)\n",
    "\n",
    "        no_under_predict = 0\n",
    "        no_over_predict = 0\n",
    "\n",
    "        for i in range(number_test_set):\n",
    "            count = 0\n",
    "            for k in range(dim):\n",
    "                if test_target[i][k] == 0.5:\n",
    "                    cluster_index = k\n",
    "                    break\n",
    "\n",
    "            for k in range(dim):\n",
    "                if all_adjust_predict[i][k] == 0.5:\n",
    "                    predict_index = k\n",
    "                    break\n",
    "            if predict_index < cluster_index:\n",
    "                no_under_predict = no_under_predict + 1\n",
    "            if predict_index > cluster_index:\n",
    "                no_over_predict = no_over_predict + 1\n",
    "            \n",
    "            for j in range(dim):\n",
    "                if all_adjust_predict[i][j] == test_target[i][j]:\n",
    "                    count = count + 1\n",
    "            if count == dim:\n",
    "                count_same_answer = count_same_answer + 1\n",
    "                accuracy_cluster[cluster_index] = accuracy_cluster[cluster_index] + 1\n",
    "            else:\n",
    "                wrong_predict.append(i)\n",
    "                \n",
    "    \n",
    "        adjust_accuracy = 100*count_same_answer/number_test_set\n",
    "\n",
    "        for i in range(dim):\n",
    "            if pattern_cluster[i] > 0:\n",
    "                accuracy_cluster[i] = accuracy_cluster[i]*100/pattern_cluster[i]\n",
    "            else:\n",
    "                accuracy_cluster[i] = -1\n",
    "        \n",
    "        if print_wrong_prediction == 'yes':\n",
    "            size = len(wrong_predict)\n",
    "            print(\"----- wrong prediction\")\n",
    "            for i in range(size):\n",
    "                index = wrong_predict[i]\n",
    "                print(\"\\Predicted = %s\\n\" % (predict_output_test[index]), \"target = %s\\n\" % \\\n",
    "                      (test_target[index]))\n",
    "\n",
    "        return all_adjust_predict,adjust_accuracy, accuracy_cluster, no_under_predict, no_over_predict\n",
    "\n",
    "    if target_defined == 'no':\n",
    "        adjust_accuracy = -1\n",
    "        no_under_predict = -1\n",
    "        no_over_predict = -1\n",
    "        return all_adjust_predict,adjust_accuracy, accuracy_cluster, no_under_predict, no_over_predict\n",
    "\n",
    "# #------------------------------------------------------------------------------\n",
    "def separate_specific_one_test_data(all_train_data, all_target_data, \\\n",
    "                                    test_cluster_no, test_dataset_no):\n",
    "    \n",
    "    size_train_data = len(all_train_data)\n",
    "    temp_all_train_data = copy.deepcopy(all_train_data)\n",
    "    temp_all_train_target = copy.deepcopy(all_target_data)\n",
    "    \n",
    "    X_all_train_data = []\n",
    "    X_all_train_target = []\n",
    "    X_all_test_data = []\n",
    "    X_all_test_target = []\n",
    "    \n",
    "    for i in range(size_train_data):\n",
    "        cluster_no = temp_all_train_data[i][0]\n",
    "        dataset_no = temp_all_train_data[i][1]\n",
    "        if test_cluster_no == cluster_no and test_dataset_no == dataset_no:\n",
    "            X_all_test_data.append(temp_all_train_data[i])\n",
    "            X_all_test_target.append(temp_all_train_target[i])\n",
    "        else:\n",
    "            X_all_train_data.append(temp_all_train_data[i])\n",
    "            X_all_train_target.append(temp_all_train_target[i])\n",
    "        \n",
    "\n",
    "    return X_all_train_data, X_all_test_data, X_all_train_target, \\\n",
    "           X_all_test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "import ast\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_linnerud\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import make_friedman2\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel\n",
    "import time\n",
    "\n",
    "import time as tm\n",
    "from resource import *\n",
    "\n",
    "def train_test(max_number_of_cluster,paths,number_dimension,real_n,min_rp,max_rp,fold_num,C_x):\n",
    "    print(\"read training data\")\n",
    "    train_data = []\n",
    "    train_feature_vector = []\n",
    "    train_target = []\n",
    "    #bitlength = total_cluster.bit_length()\n",
    "    bitlength = max_number_of_cluster\n",
    "    all_train_data = []\n",
    "    all_target_data = []\n",
    "    all_train_result=[]\n",
    "    predicted_class=[]\n",
    "    prediction_times = []  # List to store prediction times for each fold\n",
    "    # Lists to store performance metrics over 100 repetitions\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    mcc_scores = [] \n",
    "\n",
    "    input_file_name = f\"{paths}/encode-all-cluster.txt\"\n",
    "    print(input_file_name)\n",
    "\n",
    "    count = -1\n",
    "    with open(input_file_name,'r') as train_data_file:   \n",
    "        for line in train_data_file:\n",
    "            data = line.split()\n",
    "            dim = len(data)\n",
    "            inputdim = dim - bitlength - 2 #-- 2: cluster_no and dataset_no ---\n",
    "            train_feature_vector = []\n",
    "            cluster_name_bitpattern = []\n",
    "            cluster_no = int(data[0])\n",
    "            dataset_no = int(data[1])\n",
    "            train_feature_vector.append(cluster_no)\n",
    "            train_feature_vector.append(dataset_no)\n",
    "            for j in range(2,inputdim+2):\n",
    "                coordinate = float(data[j])\n",
    "                train_feature_vector.append(coordinate)\n",
    "            temp1 = copy.deepcopy(train_feature_vector)\n",
    "            train_data.append(temp1)\n",
    "            all_train_data.append(temp1)\n",
    "\n",
    "            for k in range(bitlength):\n",
    "                bitnumber = float(data[k+inputdim+2])\n",
    "                cluster_name_bitpattern.append(bitnumber)\n",
    "            temp2 = copy.deepcopy(cluster_name_bitpattern)\n",
    "            train_target.append(temp2) #----- modify --------\n",
    "            all_target_data.append(temp2)\n",
    "                \n",
    "    train_data_file.close()\n",
    "\n",
    "    #-------------------------------------------------------#\n",
    "    # Select test 100 \n",
    "    no_test_pattern = 1\n",
    "    no_train_pattern = len(all_train_data)\n",
    "    test_percent = no_test_pattern/no_train_pattern\n",
    "    train_percent = 1.0 - test_percent\n",
    "    average_accuracy = 0\n",
    "    print(\"train : test = \", train_percent*100, \":\", test_percent*100)\n",
    "\n",
    "    #####################################################################\n",
    "    ################ Assign the number of Fold \n",
    "    #####################################################################\n",
    "\n",
    "    fold_number = fold_num\n",
    "    print(\"----- start training and testing: \", fold_number, \" fold\")\n",
    "\n",
    "    all_adjust_predict_fold=[]\n",
    "    fold_sol=[]\n",
    "    fold_clus=[]\n",
    "    modified_values_test=[]\n",
    "    predicted_class=[]\n",
    "    \n",
    "    \n",
    "    start=1\n",
    "    \n",
    "    print('All train:',len(all_train_data))\n",
    "    time_per_fold = []\n",
    "    memory_per_fold = []\n",
    "\n",
    "    for k in range(start,fold_number+1):\n",
    "        print(\"\\n\\n=======================================================\")\n",
    "        fout = open(f'{paths}/predict-number-cluster-result_{start}_{C_x}.txt', 'a')  # Open file in append mode\n",
    "        fout.write(f\"----- fold {k} -----\\n\")\n",
    "        print(f\"-------------- fold no. : {k}\")\n",
    "        print(\"number dimension: \", number_dimension)\n",
    "\n",
    "        test_set_separate_type = 1\n",
    "    #------------- get encoded iris data in encode-all-cluster file ------- \n",
    "        if test_set_separate_type == 1:\n",
    "            test_cluster_no = real_n  #---- 6\n",
    "            # test_dataset_no = random.randint(min_rp,max_rp) #---- 1\n",
    "            test_dataset_no=min_rp+k-1\n",
    "            print(f\"Processing dataset number: {test_dataset_no}\")\n",
    "\n",
    "            print(\"----- test specific pattern in encode test data\")\n",
    "            print(\"cluster no:\", test_cluster_no, \"dataset no:\", test_dataset_no)\n",
    "            \n",
    "            Xtrain_input, Xtest_input, Xtrain_target, Xtest_target = \\\n",
    "                separate_specific_one_test_data(all_train_data, all_target_data, \\\n",
    "                                            test_cluster_no, test_dataset_no)\n",
    "            size_Xtrain_input = len(Xtrain_input)\n",
    "            size_Xtest_input = len(Xtest_input)\n",
    "            \n",
    "            # print('size_Xtrain_input',size_Xtrain_input)\n",
    "            # print('size_Xtest_input',size_Xtest_input )\n",
    "           \n",
    "                \n",
    "        if test_set_separate_type == 2: #--- delete cluster 6 dataset 1 -----\n",
    "            Xtrain_input = []\n",
    "            Xtrain_target = []\n",
    "            Xtest_input = []\n",
    "            Xtest_target = []\n",
    "            state_value = random.randint(1,100)\n",
    "\n",
    "        \n",
    "            train_input, test_input, train_target, test_target = train_test_split(\\\n",
    "                    all_train_data, all_target_data, train_size = train_percent,\\\n",
    "                    test_size = test_percent, random_state = state_value, \\\n",
    "                    shuffle = True) \n",
    "\n",
    "            Xtrain_input = copy.deepcopy(train_input)\n",
    "            Xtrain_target = copy.deepcopy(train_target)\n",
    "            Xtest_input = copy.deepcopy(test_input)\n",
    "            Xtest_target = copy.deepcopy(test_target)\n",
    "        \n",
    "            size_Xtrain_input = len(Xtrain_input)\n",
    "            size_Xtest_input = len(Xtest_input)\n",
    "        \n",
    "        test_cluster_dataset_list = []\n",
    "        for j in range(size_Xtest_input):\n",
    "            test_cluster_dataset_list.append([Xtest_input[j][0],Xtest_input[j][1]])\n",
    "            \n",
    "        for j in range(size_Xtrain_input):\n",
    "            del Xtrain_input[j][0]\n",
    "            del Xtrain_input[j][0]\n",
    "\n",
    "        for j in range(size_Xtest_input):\n",
    "            del Xtest_input[j][0] #---- remove cluster no. ----------\n",
    "            del Xtest_input[j][0]\n",
    "\n",
    "     \n",
    "        #### Train Test Model        \n",
    "        print(\"regressorchian: multi.fit(Xtrain_input,Xtrain_target)\")\n",
    "        \n",
    "        \n",
    "        multi = RegressorChain(SVR(kernel='rbf', C=C_x, tol=0.001, gamma='scale', epsilon=0.1)) #defalut\n",
    "\n",
    "        multi.fit(Xtrain_input, Xtrain_target)\n",
    "        \n",
    "       \n",
    "        # Record time before predictions\n",
    "        start_time = time.time()\n",
    "        now = time.asctime()\n",
    "        time_stamp = now.split(' ')\n",
    "        hour = now.split(' ')[3]\n",
    "        time_stamp[3] = '-'.join(hour.split(':'))\n",
    "\n",
    "        time_stamp = '_'.join(time_stamp[1:-1])\n",
    "        # start_time = tm.time()\n",
    "        Xpredict_test = multi.predict(Xtest_input)      \n",
    "       \n",
    "        running_info = getrusage(RUSAGE_SELF)\n",
    "        _time = (time.time() - start_time) #running_info.ru_utime + running_info.ru_stime\n",
    "        hour = _time // 3600\n",
    "        minutes = (_time  - (3600 * hour)) // 60\n",
    "        seconds = _time - (hour * 3600) - (minutes * 60)\n",
    "        memory = (running_info.ru_maxrss/1e6)\n",
    "        timess=[hour,minutes,seconds]\n",
    "        time_per_fold.append(_time)\n",
    "        memory_per_fold.append(memory)\n",
    "        print(f'Summary_Files: {int(hour)}:{int(minutes)}:{round(seconds)} (hh:mm:ss) and {memory} (GB)')\n",
    "    \n",
    "        print(f'Fold {k}: {int(hour)}:{int(minutes)}:{round(seconds)} (hh:mm:ss) and {memory} (GB)')\n",
    "        \n",
    "            \n",
    "        #### Calculate performance\n",
    "        # Count the occurrences of 0.5 in each column\n",
    "        all_adjust_predict, adjust_accuracy, accuracy_cluster, no_under_predict, no_over_predict = \\\n",
    "        adjust_predict_output(Xpredict_test, Xtest_target, print_adjust='yes', print_wrong_prediction='yes', target_defined='no')\n",
    "        y_pred = np.array(all_adjust_predict[0])\n",
    "        y_test = np.array(Xtest_target[0])\n",
    "        # Convert lists to NumPy arrays\n",
    "        y_pred = np.argmax(y_pred, axis=1) if y_pred.ndim ==0.5 else np.ceil(y_pred).astype(int)\n",
    "        y_test= np.argmax(y_test, axis=1) if y_test.ndim ==0.5 else np.ceil(y_test).astype(int)\n",
    "\n",
    "        print('y_pred',y_pred)   \n",
    "        print('y_test',y_test)    \n",
    "        \n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "        recalls.append(recall_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "        mcc_scores.append(matthews_corrcoef(y_test, y_pred))\n",
    "        \n",
    "\n",
    "        transposed_data = np.array(all_adjust_predict).T\n",
    "\n",
    "        # Count the occurrences of 0.5 in each column\n",
    "        counts_0_5 = [list(column).count(0.5) for column in transposed_data]\n",
    "\n",
    "        # Find the column index with the maximum count of 0.5\n",
    "        max_count_index = counts_0_5.index(max(counts_0_5))\n",
    "        print(\"Column with the maximum count of 0.5:\", max_count_index)\n",
    "        # Print the index of the column with the maximum count of 0.5\n",
    "    \n",
    "        \n",
    "        fold_sol.append(counts_0_5)\n",
    "        fold_clus.append(max_count_index+1)\n",
    "        predicted_class.append(max_count_index + 1)\n",
    "        print(fold_clus)\n",
    "        # print(\"Indices of 0.5:\", counts_0_5 )\n",
    "        print(f\"Fold_{k}_predicted: the number of class is {max_count_index + 1}\", end=\" \")\n",
    "\n",
    "    #----------------------------------------- use the original labels\n",
    "        print(\" \")\n",
    "        print(\"total adjust accuracy:\", adjust_accuracy, \"%\\n\")\n",
    "        adjust_accuracy\n",
    "        dim = len(Xtest_target[0])\n",
    "        for i in range(dim):\n",
    "            print(\"cluster \", i+1, \" accuracy: \", accuracy_cluster[i], \"%\")\n",
    "            if accuracy_cluster[i] > -1:\n",
    "                accuracy = accuracy_cluster[i]\n",
    "                no_cluster = i+1\n",
    "  \n",
    "        fout.write(f\"The predicted number from fold {k} : {max_count_index + 1}\\n\")\n",
    "    fout.write(f\"The predicted number from fold 1-{k} : {predicted_class}\\n\")\n",
    "   \n",
    "    counter = Counter(predicted_class)\n",
    "    most_common = counter.most_common(1)[0]  # Get the most common element and its count\n",
    "\n",
    "    most_frequent_number = most_common[0]\n",
    "    frequency = most_common[1]\n",
    "    acc = (frequency/len(predicted_class))*100\n",
    "\n",
    "    print('Times',time_per_fold)\n",
    "    print('Memory',memory_per_fold)\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Times',sum(time_per_fold))\n",
    "    print('Memory',np.average(memory_per_fold))\n",
    "    \n",
    "    print(f\"The most frequent number is: {most_frequent_number} with a count of: {frequency}\")\n",
    "    print(counter)\n",
    "    fout.write(f\"All results : {counter}\\n\")\n",
    "    fout.write(f\"The most predicted number from fold 1-{k} : {most_frequent_number} with a count of: {frequency}\\n\")\n",
    "    fout.write(f\"Accuracy of {most_frequent_number}: {acc}\\n\")\n",
    "    fout.write(f\"The most predicted number from fold 1-{k} : {most_frequent_number} with a count of: {frequency}\\n\")\n",
    "    fout.write(f\"Accuracy of {most_frequent_number}: {acc}\\n\")\n",
    "       \n",
    "    fout.write(f\"Times 1-{k} : {time_per_fold}\\n\")\n",
    "    fout.write(f\"Times 1-{k} total: {sum(time_per_fold)}\\n\")\n",
    "    fout.write(f\"Memory_per_fold 1-{k} : {memory_per_fold}\\n\")\n",
    "    fout.write(f\"Memory_per_fold 1-{k} average: {np.average(memory_per_fold)}\\n\")\n",
    "    ######################### \n",
    "    \n",
    "    # Calculate mean and standard deviation for each metric\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "\n",
    "    mean_precision = np.mean(precisions)\n",
    "    std_precision = np.std(precisions)\n",
    "\n",
    "    mean_recall = np.mean(recalls)\n",
    "    std_recall = np.std(recalls)\n",
    "\n",
    "    mean_f1_score = np.mean(f1_scores)\n",
    "    std_f1_score = np.std(f1_scores)\n",
    "\n",
    "    mean_mcc = np.mean(mcc_scores)\n",
    "    std_mcc = np.std(mcc_scores)\n",
    "    \n",
    "    fout.write(f\"\\n\")\n",
    "    fout.write(f\"Summary Results: For folds 1-{fold_num}\\n\")\n",
    "    fout.write(f\"mean_accuracy : {mean_accuracy}\\n\")\n",
    "    fout.write(f\"std_accuracy  : {std_accuracy}\\n\")\n",
    "    fout.write(f\"mean_precision: {mean_precision}\\n\")\n",
    "    fout.write(f\"std_precision : {std_precision }\\n\")\n",
    "    fout.write(f\"mean_recall   : {mean_recall}\\n\")\n",
    "    fout.write(f\"std_recall    : {std_recall }\\n\")\n",
    "    fout.write(f\"mean_f1_score : {mean_f1_score}\\n\")\n",
    "    fout.write(f\"std_f1_score  : {std_f1_score}\\n\")\n",
    "    fout.write(f\"mean_mcc : {mean_mcc}\\n\")\n",
    "    fout.write(f\"std_mcc  : {std_mcc}\\n\")\n",
    "    fout.close()\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def train_test_train(max_number_of_cluster,paths,number_dimension,real_n,min_rp,max_rp,fold_num,C_x):\n",
    "    print(\"read training data\")\n",
    "    train_data = []\n",
    "    train_feature_vector = []\n",
    "    train_target = []\n",
    "    #bitlength = total_cluster.bit_length()\n",
    "    bitlength = max_number_of_cluster\n",
    "    all_train_data = []\n",
    "    all_target_data = []\n",
    "    all_train_result=[]\n",
    "    predicted_class=[]\n",
    "    prediction_times = []  # List to store prediction times for each fold\n",
    "    # Lists to store performance metrics over 100 repetitions\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    mcc_scores = [] \n",
    "\n",
    "  \n",
    "\n",
    "    input_file_name = f\"{paths}/encode-all-cluster.txt\"\n",
    "    print(input_file_name)\n",
    "\n",
    "    count = -1\n",
    "    with open(input_file_name,'r') as train_data_file:   \n",
    "        for line in train_data_file:\n",
    "            data = line.split()\n",
    "            dim = len(data)\n",
    "            inputdim = dim - bitlength - 2 #-- 2: cluster_no and dataset_no ---\n",
    "            train_feature_vector = []\n",
    "            cluster_name_bitpattern = []\n",
    "            cluster_no = int(data[0])\n",
    "            dataset_no = int(data[1])\n",
    "            train_feature_vector.append(cluster_no)\n",
    "            train_feature_vector.append(dataset_no)\n",
    "            for j in range(2,inputdim+2):\n",
    "                coordinate = float(data[j])\n",
    "                train_feature_vector.append(coordinate)\n",
    "            temp1 = copy.deepcopy(train_feature_vector)\n",
    "            train_data.append(temp1)\n",
    "            all_train_data.append(temp1)\n",
    "\n",
    "            for k in range(bitlength):\n",
    "                bitnumber = float(data[k+inputdim+2])\n",
    "                cluster_name_bitpattern.append(bitnumber)\n",
    "            temp2 = copy.deepcopy(cluster_name_bitpattern)\n",
    "            train_target.append(temp2) #----- modify --------\n",
    "            all_target_data.append(temp2)\n",
    "                \n",
    "    train_data_file.close()\n",
    "\n",
    "    #-------------------------------------------------------#\n",
    "    no_test_pattern = 1\n",
    "    no_train_pattern = len(all_train_data)\n",
    "    test_percent = no_test_pattern/no_train_pattern\n",
    "    train_percent = 1.0 - test_percent\n",
    "    average_accuracy = 0\n",
    "    print(\"train : test = \", train_percent*100, \":\", test_percent*100)\n",
    "\n",
    "    #####################################################################\n",
    "    ################ Assign the number of Fold \n",
    "    #####################################################################\n",
    "\n",
    "    # fold_number = int(fold_num/20)\n",
    "    fold_number = 3\n",
    "    print(\"----- start training and testing: \", fold_number, \" fold\")\n",
    "\n",
    "    all_adjust_predict_fold=[]\n",
    "    fold_sol=[]\n",
    "    fold_clus=[]\n",
    "    modified_values_test=[]\n",
    "    predicted_class=[]\n",
    "    count_pre_list=[]\n",
    "    \n",
    "    start=1\n",
    "    count_pre=0\n",
    "    fold_number=fold_number\n",
    "    \n",
    "    \n",
    "    print('All train:',len(all_train_data))\n",
    "    time_per_fold = []\n",
    "    memory_per_fold = []\n",
    "\n",
    "    for k in range(start,fold_number+1):\n",
    "        test_dataset_no=min_rp+k-1\n",
    "        print(\"\\n\\n=======================================================\")\n",
    "        fout = open(f'{paths}/predict-number-cluster-result_{start}_Train_{C_x}.txt', 'a')  # Open file in append mode\n",
    "        fout.write(f\"----- fold {k} -----\\n\")\n",
    "        print(f\"-------------- fold no. : {k}\")\n",
    "        print(\"number dimension: \", number_dimension)\n",
    "\n",
    "        test_set_separate_type = 1\n",
    "    #------------- get encoded iris data in encode-all-cluster file ------- \n",
    "        if test_set_separate_type == 1:\n",
    "            test_cluster_no = real_n  #---- 6\n",
    "            # test_dataset_no = random.randint(min_rp,max_rp) #---- 1\n",
    "            # for test_dataset_no in range(min_rp, max_rp + 1):  # Loop through all values from min_rp to max_rp (inclusive)\n",
    "            test_dataset_no=min_rp+k-1\n",
    "            print(f\"Processing dataset number: {test_dataset_no}\")\n",
    "\n",
    "            print(\"----- test specific pattern in encode test data\")\n",
    "            print(\"cluster no:\", test_cluster_no, \"dataset no:\", test_dataset_no)\n",
    "            \n",
    "            Xtrain_input, Xtest_input, Xtrain_target, Xtest_target = \\\n",
    "                separate_specific_one_test_data(all_train_data, all_target_data, \\\n",
    "                                            test_cluster_no, test_dataset_no)\n",
    "            size_Xtrain_input = len(Xtrain_input)\n",
    "            size_Xtest_input = len(Xtest_input)\n",
    "            \n",
    "            # print('size_Xtrain_input',size_Xtrain_input)\n",
    "            # print('size_Xtest_input',size_Xtest_input )\n",
    "           \n",
    "                \n",
    "        if test_set_separate_type == 2: #--- delete cluster 6 dataset 1 -----\n",
    "            Xtrain_input = []\n",
    "            Xtrain_target = []\n",
    "            Xtest_input = []\n",
    "            Xtest_target = []\n",
    "            state_value = random.randint(1,100)\n",
    "\n",
    "        \n",
    "            train_input, test_input, train_target, test_target = train_test_split(\\\n",
    "                    all_train_data, all_target_data, train_size = train_percent,\\\n",
    "                    test_size = test_percent, random_state = state_value, \\\n",
    "                    shuffle = True) \n",
    "\n",
    "            Xtrain_input = copy.deepcopy(train_input)\n",
    "            Xtrain_target = copy.deepcopy(train_target)\n",
    "            Xtest_input = copy.deepcopy(test_input)\n",
    "            Xtest_target = copy.deepcopy(test_target)\n",
    "        \n",
    "            size_Xtrain_input = len(Xtrain_input)\n",
    "            size_Xtest_input = len(Xtest_input)\n",
    "        \n",
    "        test_cluster_dataset_list = []\n",
    "        for j in range(size_Xtest_input):\n",
    "            test_cluster_dataset_list.append([Xtest_input[j][0],Xtest_input[j][1]])\n",
    "            \n",
    "        for j in range(size_Xtrain_input):\n",
    "            del Xtrain_input[j][0]\n",
    "            del Xtrain_input[j][0]\n",
    "\n",
    "        for j in range(size_Xtest_input):\n",
    "            del Xtest_input[j][0] #---- remove cluster no. ----------\n",
    "            del Xtest_input[j][0]\n",
    "\n",
    "        \n",
    "        # no_hidden_neuron = 211        \n",
    "        #   # Record start time for prediction\n",
    "        # # start_time = tm.time()\n",
    "        # Xpredict_output_test,all_adjust_predict,accuracy_cluster, no_under_predict, no_over_predict=\\\n",
    "        # train_network(Xtrain_input, Xtrain_target, Xtest_input, Xtest_target,k,no_hidden_neuron,max_number_of_cluster,paths)\n",
    "        \n",
    "        #### Train Test Model        \n",
    "        print(\"regressorchian: multi.fit(Xtrain_input,Xtrain_target)\")\n",
    "        \n",
    "        # order_permutation = [3, 2, 1, 0]                   \n",
    "        multi = RegressorChain(SVR(kernel='rbf', C=C_x, tol=0.001, gamma='scale', epsilon=0.1)) #defalut\n",
    "        # multi = MLPRegressor(activation='relu', hidden_layer_sizes=(1000,1000), alpha=0.001, \n",
    "        #            shuffle=True, max_iter=5000)\n",
    "        multi.fit(Xtrain_input, Xtrain_target)       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #    ############################################# Check 100% accuracy?\n",
    "    #     # Make predictions on the training data\n",
    "    #     Xpredict_train = multi.predict(Xtrain_input)\n",
    "\n",
    "     \n",
    "    #     all_adjust_predict, adjust_accuracy, accuracy_cluster, no_under_predict, no_over_predict = \\\n",
    "    #     adjust_predict_output(Xpredict_train, Xtrain_target, print_adjust='yes', print_wrong_prediction='yes', target_defined='no')\n",
    "    #     X_pred_train = np.array(all_adjust_predict[0])\n",
    "    #     X_train_tar = np.array(Xtrain_target[0])\n",
    "    #     y_pred_train = np.argmax(X_pred_train, axis=1) if X_pred_train.ndim ==0.5 else np.ceil(X_pred_train).astype(int)\n",
    "    #     y_test_train= np.argmax( X_train_tar, axis=1) if  X_train_tar.ndim ==0.5 else np.ceil(X_train_tar).astype(int)\n",
    "        \n",
    "    #     # Compare predicted values to actual target values\n",
    "    #     print('X_pred_train',y_pred_train )\n",
    "    #     print(' X_train_tar ',  y_test_train)\n",
    "        \n",
    "    #     train_accuracy = accuracy_score(X_train_tar , y_pred_train )\n",
    "\n",
    "    #     # Print the accuracy\n",
    "    #     print('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n",
    "    #     print(f\"Training accuracy: {train_accuracy * 100:.2f}%\")\n",
    "    #     print( )\n",
    "        \n",
    "        # # Check if training accuracy is 100%\n",
    "        # if train_accuracy == 1.0:\n",
    "        #     print(\"The model has achieved 100% accuracy on the training data.\")\n",
    "        # else:\n",
    "        #     print(\"The model has not achieved 100% accuracy on the training data.\")\n",
    "\n",
    "     \n",
    "        # Record time before predictions\n",
    "        start_time = time.time()\n",
    "        now = time.asctime()\n",
    "        time_stamp = now.split(' ')\n",
    "        hour = now.split(' ')[3]\n",
    "        time_stamp[3] = '-'.join(hour.split(':'))\n",
    "\n",
    "        time_stamp = '_'.join(time_stamp[1:-1])\n",
    "        # start_time = tm.time()\n",
    "        ##################################################################################################################################\n",
    "        # Xpredict_test = multi.predict(Xtest_input)\n",
    "        Xpredict_test = multi.predict(Xtrain_input)\n",
    "        \n",
    "        # print(Xpredict_test)\n",
    "        # print()\n",
    "        # print(Xtrain_target)\n",
    "\n",
    "        # Record time after predictions\n",
    "     \n",
    "        # end_time = tm.time()\n",
    "        \n",
    "        # prediction_time = end_time - start_time\n",
    "        # print(f\"Prediction time: {prediction_time:.2f} seconds\")\n",
    "        \n",
    "        # print(\"\\nXpredict test\")\n",
    "        # print(Xpredict_test)\n",
    "        # print(\"\\nXtest target\")\n",
    "        # print(test_target)        \n",
    "       \n",
    "        running_info = getrusage(RUSAGE_SELF)\n",
    "        _time = (time.time() - start_time) #running_info.ru_utime + running_info.ru_stime\n",
    "        hour = _time // 3600\n",
    "        minutes = (_time  - (3600 * hour)) // 60\n",
    "        seconds = _time - (hour * 3600) - (minutes * 60)\n",
    "        memory = (running_info.ru_maxrss/1e6)\n",
    "        timess=[hour,minutes,seconds]\n",
    "        time_per_fold.append(_time)\n",
    "        memory_per_fold.append(memory)\n",
    "        print(f'Summary_Files: {int(hour)}:{int(minutes)}:{round(seconds)} (hh:mm:ss) and {memory} (GB)')\n",
    "    \n",
    "        print(f'Fold {k}: {int(hour)}:{int(minutes)}:{round(seconds)} (hh:mm:ss) and {memory} (GB)')\n",
    "        \n",
    "        Xtest_target = Xtrain_target\n",
    "        #### Calculate performance\n",
    "        # Count the occurrences of 0.5 in each column\n",
    "        all_adjust_predict, adjust_accuracy, accuracy_cluster, no_under_predict, no_over_predict = \\\n",
    "        adjust_predict_output(Xpredict_test, Xtest_target, print_adjust='yes', print_wrong_prediction='yes', target_defined='no')\n",
    "        y_pred = np.array(all_adjust_predict)\n",
    "        y_test = np.array(Xtest_target)\n",
    "        # y_pred = np.array(all_adjust_predict[0])\n",
    "        # y_test = np.array(Xtest_target[0])\n",
    "        # Convert lists to NumPy arrays\n",
    "        y_pred = np.argmax(y_pred, axis=1) if y_pred.ndim ==0.5 else np.ceil(y_pred).astype(int)\n",
    "        y_test= np.argmax(y_test, axis=1) if y_test.ndim ==0.5 else np.ceil(y_test).astype(int)\n",
    "\n",
    "        # print('y_pred: ',y_pred)   \n",
    "        # print('y_test: ',y_test)   \n",
    "        \n",
    "        # Check if the shapes match\n",
    "        if y_pred.shape == y_test.shape:\n",
    "            # Compare element-wise\n",
    "            comparison = np.isclose(y_pred, y_test)\n",
    "            \n",
    "            # Check each row (sublist) for all True\n",
    "            match_counts = [1 if np.all(row) else 0 for row in comparison]\n",
    "\n",
    "            print(\"Element-wise comparison:\\n\", comparison)\n",
    "            print(\"Match count for each sublist (1 if all True, 0 otherwise):\", match_counts)\n",
    "        else:\n",
    "            print(\"The shapes of y_pred and y_test do not match.\")\n",
    "\n",
    "        train_accuracy = (np.sum(match_counts) / y_test.shape[0]) * 100\n",
    "        print('Sum',np.sum(match_counts))\n",
    "        print('Y-test_shape',y_test.shape[0])\n",
    "        \n",
    "        # Print train accuracy with two decimal places\n",
    "        print('Train accuracy: {:.2f}%'.format(train_accuracy))\n",
    "\n",
    "        # Append the rounded train accuracy to the list\n",
    "        count_pre_list.append(round(train_accuracy, 2))\n",
    "        \n",
    "        # accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        # precisions.append(precision_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "        # recalls.append(recall_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "        # f1_scores.append(f1_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "        # mcc_scores.append(matthews_corrcoef(y_test, y_pred))\n",
    "        \n",
    "\n",
    "\n",
    "        # Transpose the data to get columns\n",
    "        transposed_data = np.array(all_adjust_predict).T\n",
    "\n",
    "        # Count the occurrences of 0.5 in each column\n",
    "        counts_0_5 = [list(column).count(0.5) for column in transposed_data]\n",
    "\n",
    "        # Find the column index with the maximum count of 0.5\n",
    "        max_count_index = counts_0_5.index(max(counts_0_5))\n",
    "        print(\"Column with the maximum count of 0.5:\", max_count_index)\n",
    "        # Print the index of the column with the maximum count of 0.5\n",
    "    \n",
    "        \n",
    "        fold_sol.append(counts_0_5)\n",
    "        fold_clus.append(max_count_index+1)\n",
    "        predicted_class.append(max_count_index + 1)\n",
    "        print(fold_clus)\n",
    "        # print(\"Indices of 0.5:\", counts_0_5 )\n",
    "        print(f\"Fold_{k}_predicted: the number of class is {max_count_index + 1}\", end=\" \")\n",
    "\n",
    "    #----------------------------------------- use the original labels\n",
    "        print(\" \")\n",
    "        print(\"total adjust accuracy:\", adjust_accuracy, \"%\\n\")\n",
    "        adjust_accuracy\n",
    "        dim = len(Xtest_target[0])\n",
    "        for i in range(dim):\n",
    "            print(\"cluster \", i+1, \" accuracy: \", accuracy_cluster[i], \"%\")\n",
    "            if accuracy_cluster[i] > -1:\n",
    "                accuracy = accuracy_cluster[i]\n",
    "                no_cluster = i+1\n",
    "        # print(\"fold:\", k, \"cluster:\", cluster_no, \" dataset:\", dataset_no,\\\n",
    "        #     \"accuracy:\", accuracy)\n",
    "        # print(\"number of under-predicted patterns: \", no_under_predict)\n",
    "        # print(\"number of over-predicted patterns: \", no_over_predict)\n",
    "        \n",
    "        fout.write(f\"The predicted number from fold {k} : {max_count_index + 1}\\n\")\n",
    "    fout.write(f\"The predicted number from fold 1-{k} : {predicted_class}\\n\")\n",
    "   \n",
    "    counter = Counter(predicted_class)\n",
    "    most_common = counter.most_common(1)[0]  # Get the most common element and its count\n",
    "\n",
    "    most_frequent_number = most_common[0]\n",
    "    frequency = most_common[1]\n",
    "    acc = (frequency/len(predicted_class))*100\n",
    "\n",
    "    print('Times',time_per_fold)\n",
    "    print('Memory',memory_per_fold)\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Times',sum(time_per_fold))\n",
    "    print('Memory',np.average(memory_per_fold))\n",
    "    \n",
    "    print(f\"The most frequent number is: {most_frequent_number} with a count of: {frequency}\")\n",
    "    print(counter)\n",
    "    fout.write(f\"All results : {counter}\\n\")\n",
    "    fout.write(f\"The most predicted number from fold 1-{k} : {most_frequent_number} with a count of: {frequency}\\n\")\n",
    "    fout.write(f\"Accuracy of {most_frequent_number}: {acc}\\n\")\n",
    "    fout.write(f\"The most predicted number from fold 1-{k} : {most_frequent_number} with a count of: {frequency}\\n\")\n",
    "    fout.write(f\"Accuracy of {most_frequent_number}: {acc}\\n\")\n",
    "       \n",
    "    fout.write(f\"Times 1-{k} : {time_per_fold}\\n\")\n",
    "    fout.write(f\"Times 1-{k} total: {sum(time_per_fold)}\\n\")\n",
    "    fout.write(f\"Memory_per_fold 1-{k} : {memory_per_fold}\\n\")\n",
    "    fout.write(f\"Memory_per_fold 1-{k} average: {np.average(memory_per_fold)}\\n\")\n",
    "    ######################### \n",
    "    \n",
    "    print('count_pre_list',count_pre_list) \n",
    "    print('accuracy_mean',np.mean(count_pre_list) )\n",
    "    fout.write(f\"accuracy_all  : {count_pre_list}\\n\")\n",
    "    fout.write(f\"accuracy_mean  : {np.mean(count_pre_list)}\\n\")\n",
    "    fout.close()\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer = 6\n",
    "\n",
    "n_components=5\n",
    "\n",
    "number_dimension= n_components\n",
    "\n",
    "\n",
    "n_real= 3\n",
    "\n",
    "\n",
    "num_p= 400\n",
    "\n",
    "num_real = 300\n",
    "\n",
    "start_gen_gaussian_train_data_set = 1\n",
    "end_gen_gaussian_train_data_set   = num_p\n",
    "\n",
    "start_gen_real_train_data_set = num_p-num_real +1\n",
    "end_gen_real_train_data_set  = num_p\n",
    "\n",
    "\n",
    "start_cluster           = 1\n",
    "max_number_of_cluster   = 10\n",
    "\n",
    "start_add_point_train_data_set = 1\n",
    "end_add_point_train_data_set   = num_p\n",
    "\n",
    "start_encode_train_data_set  = 1\n",
    "end_encode_train_data_set    = num_p\n",
    "\n",
    "\n",
    "increase_r = 3\n",
    "\n",
    "fold_num = 100\n",
    "\n",
    "C_x=1.0\n",
    "\n",
    "path='/home/admin1/Program5_Test2024/iDeLUCS-master/Example'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name='mtInsects'\n",
    "name='balanced_mtInsects'\n",
    "# name='Cyprinidae'\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import csv\n",
    "from resource import *\n",
    "\n",
    "start_time = time.time()\n",
    "now = time.asctime()\n",
    "time_stamp = now.split(' ')\n",
    "hour = now.split(' ')[3]\n",
    "time_stamp[3] = '-'.join(hour.split(':'))\n",
    "\n",
    "time_stamp = '_'.join(time_stamp[1:-1])\n",
    "\n",
    "#1 Create new folder and Read files \n",
    "folder_name = os.getcwd()\n",
    "folder_name = f'{folder_name}/Results_{name}_{C_x}'\n",
    "\n",
    "if not os.path.isdir(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "\n",
    "results_folder = f'{folder_name}'\n",
    "paths= results_folder\n",
    "\n",
    "if not os.path.isdir(f'{results_folder}'):\n",
    "    os.mkdir(f'{results_folder}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  sequence_id      cluster_id\n",
      "0            559  NC_042413.1  Pezizomycotina\n",
      "1            505  NC_041489.1  Pezizomycotina\n",
      "2            434   KY792993.1  Pezizomycotina\n",
      "3            705  NC_026920.1  Pezizomycotina\n",
      "4            576   MK318967.1  Pezizomycotina\n",
      "...          ...          ...             ...\n",
      "1000        1481   MZ042935.1   Basidiomycota\n",
      "1001        1553   MN427435.1   Basidiomycota\n",
      "1002        1466  NC_026782.1   Basidiomycota\n",
      "1003        1474   LC385608.1   Basidiomycota\n",
      "1004        1743   KY911090.1   Basidiomycota\n",
      "\n",
      "[1005 rows x 3 columns]\n",
      "The cluster distribution is:\n",
      "{'Pezizomycotina': 335, 'Saccharomycotina': 335, 'Basidiomycota': 335}\n",
      "No. Sequences: \t 1,005\n",
      "Min. Length: \t 21,684\n",
      "Max. Length: \t 99,976\n",
      "Avg. Length: \t 60,656.88\n",
      "Min cluster size: 335 (Pezizomycotina, Saccharomycotina, Basidiomycota)\n",
      "Max cluster size: 335 (Pezizomycotina, Saccharomycotina, Basidiomycota)\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Number of principal components: 5\n",
      "1005\n",
      "generate gaussian training data_real\n",
      "from data set 1 - 400\n",
      "number dimension: 5\n",
      "Generate Real training data\n",
      "From dataset 101 - 400\n",
      "add train - test point\n",
      "number of encode train data in each cluster: 400\n",
      "train max point:  1005  train min point:  70\n",
      "add train point\n",
      "---- read test data and normalize each dimension\n",
      "\n",
      "test data file: /home/admin1/Program5_Test2024/Results_balanced_Fungi_1.0/preprocessed_data.txt\n",
      "encode\n",
      "number of encode pattern: 1 - 400\n",
      "/home/admin1/Program5_Test2024/Results_balanced_Fungi_1.0/encode-all-cluster.txt\n",
      "----- sort-by-dim dim: \n",
      "bitlength 10\n",
      "<class 'list'>\n",
      "number of encoded patterns: 4001\n",
      "read training data\n",
      "/home/admin1/Program5_Test2024/Results_balanced_Fungi_1.0/encode-all-cluster.txt\n",
      "train : test =  99.9750062484379 : 0.024993751562109475\n",
      "----- start training and testing:  100  fold\n",
      "All train: 4001\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 1\n",
      "number dimension:  5\n",
      "Processing dataset number: 101\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 101\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.561472 (GB)\n",
      "Fold 1: 0:0:0 (hh:mm:ss) and 2.561472 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3]\n",
      "Fold_1_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 2\n",
      "number dimension:  5\n",
      "Processing dataset number: 102\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 102\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.680608 (GB)\n",
      "Fold 2: 0:0:0 (hh:mm:ss) and 2.680608 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3]\n",
      "Fold_2_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 3\n",
      "number dimension:  5\n",
      "Processing dataset number: 103\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 103\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.74818 (GB)\n",
      "Fold 3: 0:0:0 (hh:mm:ss) and 2.74818 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3]\n",
      "Fold_3_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 4\n",
      "number dimension:  5\n",
      "Processing dataset number: 104\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 104\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.748632 (GB)\n",
      "Fold 4: 0:0:0 (hh:mm:ss) and 2.748632 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3]\n",
      "Fold_4_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 5\n",
      "number dimension:  5\n",
      "Processing dataset number: 105\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 105\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.748712 (GB)\n",
      "Fold 5: 0:0:0 (hh:mm:ss) and 2.748712 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3]\n",
      "Fold_5_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 6\n",
      "number dimension:  5\n",
      "Processing dataset number: 106\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 106\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.748752 (GB)\n",
      "Fold 6: 0:0:0 (hh:mm:ss) and 2.748752 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3]\n",
      "Fold_6_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 7\n",
      "number dimension:  5\n",
      "Processing dataset number: 107\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 107\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.748752 (GB)\n",
      "Fold 7: 0:0:0 (hh:mm:ss) and 2.748752 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_7_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 8\n",
      "number dimension:  5\n",
      "Processing dataset number: 108\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 108\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.748752 (GB)\n",
      "Fold 8: 0:0:0 (hh:mm:ss) and 2.748752 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_8_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 9\n",
      "number dimension:  5\n",
      "Processing dataset number: 109\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 109\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.748896 (GB)\n",
      "Fold 9: 0:0:0 (hh:mm:ss) and 2.748896 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_9_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 10\n",
      "number dimension:  5\n",
      "Processing dataset number: 110\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 110\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749016 (GB)\n",
      "Fold 10: 0:0:0 (hh:mm:ss) and 2.749016 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_10_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 11\n",
      "number dimension:  5\n",
      "Processing dataset number: 111\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 111\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749016 (GB)\n",
      "Fold 11: 0:0:0 (hh:mm:ss) and 2.749016 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_11_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 12\n",
      "number dimension:  5\n",
      "Processing dataset number: 112\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 112\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749016 (GB)\n",
      "Fold 12: 0:0:0 (hh:mm:ss) and 2.749016 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_12_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 13\n",
      "number dimension:  5\n",
      "Processing dataset number: 113\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 113\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749016 (GB)\n",
      "Fold 13: 0:0:0 (hh:mm:ss) and 2.749016 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_13_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 14\n",
      "number dimension:  5\n",
      "Processing dataset number: 114\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 114\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749016 (GB)\n",
      "Fold 14: 0:0:0 (hh:mm:ss) and 2.749016 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_14_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 15\n",
      "number dimension:  5\n",
      "Processing dataset number: 115\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 115\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749216 (GB)\n",
      "Fold 15: 0:0:0 (hh:mm:ss) and 2.749216 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_15_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 16\n",
      "number dimension:  5\n",
      "Processing dataset number: 116\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 116\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749296 (GB)\n",
      "Fold 16: 0:0:0 (hh:mm:ss) and 2.749296 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_16_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 17\n",
      "number dimension:  5\n",
      "Processing dataset number: 117\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 117\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.74952 (GB)\n",
      "Fold 17: 0:0:0 (hh:mm:ss) and 2.74952 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_17_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 18\n",
      "number dimension:  5\n",
      "Processing dataset number: 118\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 118\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.74952 (GB)\n",
      "Fold 18: 0:0:0 (hh:mm:ss) and 2.74952 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_18_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 19\n",
      "number dimension:  5\n",
      "Processing dataset number: 119\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 119\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.74952 (GB)\n",
      "Fold 19: 0:0:0 (hh:mm:ss) and 2.74952 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_19_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 20\n",
      "number dimension:  5\n",
      "Processing dataset number: 120\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 120\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.74952 (GB)\n",
      "Fold 20: 0:0:0 (hh:mm:ss) and 2.74952 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_20_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 21\n",
      "number dimension:  5\n",
      "Processing dataset number: 121\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 121\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749528 (GB)\n",
      "Fold 21: 0:0:0 (hh:mm:ss) and 2.749528 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_21_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 22\n",
      "number dimension:  5\n",
      "Processing dataset number: 122\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 122\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749532 (GB)\n",
      "Fold 22: 0:0:0 (hh:mm:ss) and 2.749532 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_22_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 23\n",
      "number dimension:  5\n",
      "Processing dataset number: 123\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 123\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749532 (GB)\n",
      "Fold 23: 0:0:0 (hh:mm:ss) and 2.749532 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_23_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 24\n",
      "number dimension:  5\n",
      "Processing dataset number: 124\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 124\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749532 (GB)\n",
      "Fold 24: 0:0:0 (hh:mm:ss) and 2.749532 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_24_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 25\n",
      "number dimension:  5\n",
      "Processing dataset number: 125\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 125\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749532 (GB)\n",
      "Fold 25: 0:0:0 (hh:mm:ss) and 2.749532 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_25_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 26\n",
      "number dimension:  5\n",
      "Processing dataset number: 126\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 126\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749532 (GB)\n",
      "Fold 26: 0:0:0 (hh:mm:ss) and 2.749532 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_26_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 27\n",
      "number dimension:  5\n",
      "Processing dataset number: 127\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 127\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749532 (GB)\n",
      "Fold 27: 0:0:0 (hh:mm:ss) and 2.749532 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_27_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 28\n",
      "number dimension:  5\n",
      "Processing dataset number: 128\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 128\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "Fold 28: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_28_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 29\n",
      "number dimension:  5\n",
      "Processing dataset number: 129\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 129\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "Fold 29: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_29_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 30\n",
      "number dimension:  5\n",
      "Processing dataset number: 130\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 130\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "Fold 30: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_30_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 31\n",
      "number dimension:  5\n",
      "Processing dataset number: 131\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 131\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "Fold 31: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_31_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 32\n",
      "number dimension:  5\n",
      "Processing dataset number: 132\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 132\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "Fold 32: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_32_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 33\n",
      "number dimension:  5\n",
      "Processing dataset number: 133\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 133\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "Fold 33: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_33_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 34\n",
      "number dimension:  5\n",
      "Processing dataset number: 134\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 134\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "Fold 34: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_34_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 35\n",
      "number dimension:  5\n",
      "Processing dataset number: 135\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 135\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "Fold 35: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_35_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 36\n",
      "number dimension:  5\n",
      "Processing dataset number: 136\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 136\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "Fold 36: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_36_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 37\n",
      "number dimension:  5\n",
      "Processing dataset number: 137\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 137\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "Fold 37: 0:0:0 (hh:mm:ss) and 2.749784 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_37_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 38\n",
      "number dimension:  5\n",
      "Processing dataset number: 138\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 138\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.7498 (GB)\n",
      "Fold 38: 0:0:0 (hh:mm:ss) and 2.7498 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_38_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 39\n",
      "number dimension:  5\n",
      "Processing dataset number: 139\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 139\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.749804 (GB)\n",
      "Fold 39: 0:0:0 (hh:mm:ss) and 2.749804 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_39_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 40\n",
      "number dimension:  5\n",
      "Processing dataset number: 140\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 140\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782016 (GB)\n",
      "Fold 40: 0:0:0 (hh:mm:ss) and 2.782016 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_40_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 41\n",
      "number dimension:  5\n",
      "Processing dataset number: 141\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 141\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782016 (GB)\n",
      "Fold 41: 0:0:0 (hh:mm:ss) and 2.782016 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_41_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 42\n",
      "number dimension:  5\n",
      "Processing dataset number: 142\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 142\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 42: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_42_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 43\n",
      "number dimension:  5\n",
      "Processing dataset number: 143\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 143\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 43: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_43_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 44\n",
      "number dimension:  5\n",
      "Processing dataset number: 144\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 144\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 44: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_44_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 45\n",
      "number dimension:  5\n",
      "Processing dataset number: 145\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 145\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 45: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_45_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 46\n",
      "number dimension:  5\n",
      "Processing dataset number: 146\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 146\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 46: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_46_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 47\n",
      "number dimension:  5\n",
      "Processing dataset number: 147\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 147\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 47: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_47_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 48\n",
      "number dimension:  5\n",
      "Processing dataset number: 148\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 148\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 48: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_48_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 49\n",
      "number dimension:  5\n",
      "Processing dataset number: 149\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 149\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 49: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_49_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 50\n",
      "number dimension:  5\n",
      "Processing dataset number: 150\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 150\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 50: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_50_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 51\n",
      "number dimension:  5\n",
      "Processing dataset number: 151\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 151\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 51: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_51_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 52\n",
      "number dimension:  5\n",
      "Processing dataset number: 152\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 152\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 52: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_52_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 53\n",
      "number dimension:  5\n",
      "Processing dataset number: 153\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 153\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 53: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_53_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 54\n",
      "number dimension:  5\n",
      "Processing dataset number: 154\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 154\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 54: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_54_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 55\n",
      "number dimension:  5\n",
      "Processing dataset number: 155\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 155\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 55: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_55_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 56\n",
      "number dimension:  5\n",
      "Processing dataset number: 156\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 156\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 56: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_56_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 57\n",
      "number dimension:  5\n",
      "Processing dataset number: 157\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 157\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 57: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_57_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 58\n",
      "number dimension:  5\n",
      "Processing dataset number: 158\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 158\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 58: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_58_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 59\n",
      "number dimension:  5\n",
      "Processing dataset number: 159\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 159\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 59: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_59_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 60\n",
      "number dimension:  5\n",
      "Processing dataset number: 160\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 160\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 60: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_60_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 61\n",
      "number dimension:  5\n",
      "Processing dataset number: 161\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 161\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 61: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_61_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 62\n",
      "number dimension:  5\n",
      "Processing dataset number: 162\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 162\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 62: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_62_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 63\n",
      "number dimension:  5\n",
      "Processing dataset number: 163\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 163\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 63: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_63_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 64\n",
      "number dimension:  5\n",
      "Processing dataset number: 164\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 164\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 64: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_64_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 65\n",
      "number dimension:  5\n",
      "Processing dataset number: 165\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 165\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 65: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_65_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 66\n",
      "number dimension:  5\n",
      "Processing dataset number: 166\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 166\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 66: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_66_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 67\n",
      "number dimension:  5\n",
      "Processing dataset number: 167\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 167\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 67: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_67_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 68\n",
      "number dimension:  5\n",
      "Processing dataset number: 168\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 168\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 68: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_68_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 69\n",
      "number dimension:  5\n",
      "Processing dataset number: 169\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 169\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 69: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_69_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 70\n",
      "number dimension:  5\n",
      "Processing dataset number: 170\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 170\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 70: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_70_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 71\n",
      "number dimension:  5\n",
      "Processing dataset number: 171\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 171\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 71: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_71_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 72\n",
      "number dimension:  5\n",
      "Processing dataset number: 172\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 172\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 72: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_72_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 73\n",
      "number dimension:  5\n",
      "Processing dataset number: 173\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 173\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 73: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_73_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 74\n",
      "number dimension:  5\n",
      "Processing dataset number: 174\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 174\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 74: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_74_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 75\n",
      "number dimension:  5\n",
      "Processing dataset number: 175\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 175\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 75: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_75_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 76\n",
      "number dimension:  5\n",
      "Processing dataset number: 176\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 176\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 76: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_76_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 77\n",
      "number dimension:  5\n",
      "Processing dataset number: 177\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 177\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 77: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_77_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 78\n",
      "number dimension:  5\n",
      "Processing dataset number: 178\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 178\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 78: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_78_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 79\n",
      "number dimension:  5\n",
      "Processing dataset number: 179\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 179\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 79: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_79_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 80\n",
      "number dimension:  5\n",
      "Processing dataset number: 180\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 180\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 80: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_80_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 81\n",
      "number dimension:  5\n",
      "Processing dataset number: 181\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 181\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 81: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_81_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 82\n",
      "number dimension:  5\n",
      "Processing dataset number: 182\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 182\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 82: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_82_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 83\n",
      "number dimension:  5\n",
      "Processing dataset number: 183\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 183\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 83: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_83_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 84\n",
      "number dimension:  5\n",
      "Processing dataset number: 184\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 184\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 84: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_84_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 85\n",
      "number dimension:  5\n",
      "Processing dataset number: 185\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 185\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 85: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_85_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 86\n",
      "number dimension:  5\n",
      "Processing dataset number: 186\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 186\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 86: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_86_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 87\n",
      "number dimension:  5\n",
      "Processing dataset number: 187\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 187\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 87: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_87_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 88\n",
      "number dimension:  5\n",
      "Processing dataset number: 188\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 188\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 88: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_88_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 89\n",
      "number dimension:  5\n",
      "Processing dataset number: 189\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 189\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 89: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_89_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 90\n",
      "number dimension:  5\n",
      "Processing dataset number: 190\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 190\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 90: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_90_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 91\n",
      "number dimension:  5\n",
      "Processing dataset number: 191\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 191\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 91: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_91_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 92\n",
      "number dimension:  5\n",
      "Processing dataset number: 192\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 192\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 92: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_92_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 93\n",
      "number dimension:  5\n",
      "Processing dataset number: 193\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 193\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 93: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_93_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 94\n",
      "number dimension:  5\n",
      "Processing dataset number: 194\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 194\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 94: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_94_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 95\n",
      "number dimension:  5\n",
      "Processing dataset number: 195\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 195\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 95: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_95_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 96\n",
      "number dimension:  5\n",
      "Processing dataset number: 196\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 196\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 96: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_96_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 97\n",
      "number dimension:  5\n",
      "Processing dataset number: 197\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 197\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 97: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_97_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 98\n",
      "number dimension:  5\n",
      "Processing dataset number: 198\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 198\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 98: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_98_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 99\n",
      "number dimension:  5\n",
      "Processing dataset number: 199\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 199\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 99: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_99_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 100\n",
      "number dimension:  5\n",
      "Processing dataset number: 200\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 200\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 100: 0:0:0 (hh:mm:ss) and 2.782056 (GB)\n",
      "y_pred [0 0 1 0 0 0 0 0 0 0]\n",
      "y_test [0 0 1 0 0 0 0 0 0 0]\n",
      "Column with the maximum count of 0.5: 2\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Fold_100_predicted: the number of class is 3  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "Times [0.01525425910949707, 0.015121936798095703, 0.015266656875610352, 0.015400886535644531, 0.01466512680053711, 0.015437841415405273, 0.015207767486572266, 0.015256643295288086, 0.01492619514465332, 0.01521611213684082, 0.016598939895629883, 0.015261411666870117, 0.014528751373291016, 0.015558242797851562, 0.01670384407043457, 0.01440119743347168, 0.01520681381225586, 0.015955209732055664, 0.014178037643432617, 0.014065027236938477, 0.015111684799194336, 0.015407800674438477, 0.014531135559082031, 0.014475345611572266, 0.015297412872314453, 0.014646291732788086, 0.01873016357421875, 0.014620065689086914, 0.015114784240722656, 0.01627039909362793, 0.015157461166381836, 0.014694452285766602, 0.014842748641967773, 0.014482498168945312, 0.015107393264770508, 0.014143705368041992, 0.015143394470214844, 0.014399051666259766, 0.014607429504394531, 0.015844345092773438, 0.017935991287231445, 0.014627456665039062, 0.015514373779296875, 0.014146089553833008, 0.014758110046386719, 0.016299962997436523, 0.014777183532714844, 0.01381063461303711, 0.014549016952514648, 0.0139007568359375, 0.01627039909362793, 0.014554738998413086, 0.017926454544067383, 0.015410184860229492, 0.013911247253417969, 0.0142822265625, 0.014899492263793945, 0.01458597183227539, 0.014975786209106445, 0.014596700668334961, 0.015131473541259766, 0.014116287231445312, 0.01463937759399414, 0.013560295104980469, 0.01469731330871582, 0.013941287994384766, 0.014959573745727539, 0.014373779296875, 0.015170812606811523, 0.014445066452026367, 0.014464378356933594, 0.014405250549316406, 0.016089916229248047, 0.014894247055053711, 0.014946222305297852, 0.01386117935180664, 0.014968395233154297, 0.013725757598876953, 0.01572704315185547, 0.013993024826049805, 0.014359474182128906, 0.014126300811767578, 0.014958620071411133, 0.013924598693847656, 0.014949798583984375, 0.014251947402954102, 0.014813899993896484, 0.014645814895629883, 0.0185244083404541, 0.014647960662841797, 0.02284550666809082, 0.014819860458374023, 0.014953851699829102, 0.014268159866333008, 0.015016317367553711, 0.014718294143676758, 0.015074729919433594, 0.013613224029541016, 0.014956951141357422, 0.014422416687011719]\n",
      "Memory [2.561472, 2.680608, 2.74818, 2.748632, 2.748712, 2.748752, 2.748752, 2.748752, 2.748896, 2.749016, 2.749016, 2.749016, 2.749016, 2.749016, 2.749216, 2.749296, 2.74952, 2.74952, 2.74952, 2.74952, 2.749528, 2.749532, 2.749532, 2.749532, 2.749532, 2.749532, 2.749532, 2.749784, 2.749784, 2.749784, 2.749784, 2.749784, 2.749784, 2.749784, 2.749784, 2.749784, 2.749784, 2.7498, 2.749804, 2.782016, 2.782016, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056, 2.782056]\n",
      "\n",
      "\n",
      "Times 1.5045740604400635\n",
      "Memory 2.7667392800000004\n",
      "The most frequent number is: 3 with a count of: 100\n",
      "Counter({3: 100})\n",
      "read training data\n",
      "/home/admin1/Program5_Test2024/Results_balanced_Fungi_1.0/encode-all-cluster.txt\n",
      "train : test =  99.9750062484379 : 0.024993751562109475\n",
      "----- start training and testing:  3  fold\n",
      "All train: 4001\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 1\n",
      "number dimension:  5\n",
      "Processing dataset number: 101\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 101\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:55 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 1: 0:0:55 (hh:mm:ss) and 2.782056 (GB)\n",
      "Element-wise comparison:\n",
      " [[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True False ...  True  True  True]]\n",
      "Match count for each sublist (1 if all True, 0 otherwise): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Sum 3971\n",
      "Y-test_shape 4000\n",
      "Train accuracy: 99.28%\n",
      "Column with the maximum count of 0.5: 4\n",
      "[5]\n",
      "Fold_1_predicted: the number of class is 5  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 2\n",
      "number dimension:  5\n",
      "Processing dataset number: 102\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 102\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:54 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 2: 0:0:54 (hh:mm:ss) and 2.782056 (GB)\n",
      "Element-wise comparison:\n",
      " [[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [False  True  True ...  True  True  True]]\n",
      "Match count for each sublist (1 if all True, 0 otherwise): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Sum 3971\n",
      "Y-test_shape 4000\n",
      "Train accuracy: 99.28%\n",
      "Column with the maximum count of 0.5: 4\n",
      "[5, 5]\n",
      "Fold_2_predicted: the number of class is 5  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "\n",
      "\n",
      "=======================================================\n",
      "-------------- fold no. : 3\n",
      "number dimension:  5\n",
      "Processing dataset number: 103\n",
      "----- test specific pattern in encode test data\n",
      "cluster no: 3 dataset no: 103\n",
      "regressorchian: multi.fit(Xtrain_input,Xtrain_target)\n",
      "Summary_Files: 0:0:54 (hh:mm:ss) and 2.782056 (GB)\n",
      "Fold 3: 0:0:54 (hh:mm:ss) and 2.782056 (GB)\n",
      "Element-wise comparison:\n",
      " [[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [False  True  True ...  True  True  True]]\n",
      "Match count for each sublist (1 if all True, 0 otherwise): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Sum 3971\n",
      "Y-test_shape 4000\n",
      "Train accuracy: 99.28%\n",
      "Column with the maximum count of 0.5: 4\n",
      "[5, 5, 5]\n",
      "Fold_3_predicted: the number of class is 5  \n",
      "total adjust accuracy: -1 %\n",
      "\n",
      "cluster  1  accuracy:  0 %\n",
      "cluster  2  accuracy:  0 %\n",
      "cluster  3  accuracy:  0 %\n",
      "cluster  4  accuracy:  0 %\n",
      "cluster  5  accuracy:  0 %\n",
      "cluster  6  accuracy:  0 %\n",
      "cluster  7  accuracy:  0 %\n",
      "cluster  8  accuracy:  0 %\n",
      "cluster  9  accuracy:  0 %\n",
      "cluster  10  accuracy:  0 %\n",
      "Times [54.65330386161804, 53.886239767074585, 54.0405011177063]\n",
      "Memory [2.782056, 2.782056, 2.782056]\n",
      "\n",
      "\n",
      "Times 162.58004474639893\n",
      "Memory 2.7820559999999994\n",
      "The most frequent number is: 5 with a count of: 3\n",
      "Counter({5: 3})\n",
      "count_pre_list [99.28, 99.28, 99.28]\n",
      "accuracy_mean 99.28000000000002\n"
     ]
    }
   ],
   "source": [
    "# name='Fungi'\n",
    "name='balanced_Fungi'\n",
    "# name='Cyprinidae'\n",
    "# name='Cyprinidae'\n",
    "# name='mtInsects'\n",
    "# name='balanced_mtInsects'\n",
    "# name='Protists'\n",
    "# name='Actinopterygii'\n",
    "\n",
    "# name='balanced_Protists'\n",
    "# name='Dengue'\n",
    "# name='HBV'\n",
    "# name='Dengue'\n",
    "# name='mtInsects'\n",
    "# name='balanced_mtInsects'\n",
    "# # name='Neopterygii'\n",
    "# name='Vertebrata'\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import csv\n",
    "from resource import *\n",
    "\n",
    "start_time = time.time()\n",
    "now = time.asctime()\n",
    "time_stamp = now.split(' ')\n",
    "hour = now.split(' ')[3]\n",
    "time_stamp[3] = '-'.join(hour.split(':'))\n",
    "\n",
    "time_stamp = '_'.join(time_stamp[1:-1])\n",
    "\n",
    "#1 Create new folder and Read files \n",
    "folder_name = os.getcwd()\n",
    "folder_name = f'{folder_name}/Results_{name}_{C_x}'\n",
    "\n",
    "if not os.path.isdir(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "\n",
    "results_folder = f'{folder_name}'\n",
    "paths= results_folder\n",
    "\n",
    "if not os.path.isdir(f'{results_folder}'):\n",
    "    os.mkdir(f'{results_folder}')\n",
    "        \n",
    "results_folder = f'{folder_name}'\n",
    "paths= results_folder\n",
    "\n",
    "if not os.path.isdir(f'{results_folder}'):\n",
    "    os.mkdir(f'{results_folder}')\n",
    "        \n",
    "\n",
    "fasta_file = f\"{path}/{name}.fas\"\n",
    "GT_file = f\"{path}/{name}_GT.tsv\"\n",
    "\n",
    "names, lengths, ground_truth, cluster_dis, class_ranges = SummaryFasta(fasta_file, GT_file=GT_file)\n",
    "print(\"The cluster distribution is:\")\n",
    "print (cluster_dis)\n",
    "min_size = min(cluster_dis.values())\n",
    "max_size = max(cluster_dis.values())\n",
    "\n",
    "# From cluster_dis can get min max cluster size\n",
    "min_clusters = [k for k, v in cluster_dis.items() if v == min_size]\n",
    "max_clusters = [k for k, v in cluster_dis.items() if v == max_size]\n",
    "\n",
    "\n",
    "stats = {\"n_seq\": len(lengths),\n",
    "        \"min_len\": np.min(lengths),\n",
    "        \"max_len\": np.max(lengths),\n",
    "        \"avg_len\": np.mean(lengths)}\n",
    "\n",
    "print( f'No. Sequences: \\t {stats[\"n_seq\"]:,}')\n",
    "print(f'Min. Length: \\t {stats[\"min_len\"]:,}')\n",
    "print(f'Max. Length: \\t {stats[\"max_len\"]:,}')\n",
    "print(f'Avg. Length: \\t {round(stats[\"avg_len\"],2):,}')\n",
    "print(f\"Min cluster size: {min_size} ({', '.join(min_clusters)})\")\n",
    "print(f\"Max cluster size: {max_size} ({', '.join(max_clusters)})\")\n",
    "\n",
    "# Save sequence statistics to a text file\n",
    "result_file = f\"{name}_sequence_statistics_and_cluster_distribution.txt\"\n",
    "with open(result_file, 'w') as f:\n",
    "    f.write(\"Cluster Distribution:\\n\")\n",
    "    for cluster, count in cluster_dis.items():\n",
    "        f.write(f'{cluster}: {count}\\n')\n",
    "\n",
    "    f.write(\"\\nSequence Statistics:\\n\")\n",
    "    f.write(f'No. Sequences: \\t {stats[\"n_seq\"]:,}\\n')\n",
    "    f.write(f'Min. Length: \\t {stats[\"min_len\"]:,}\\n')\n",
    "    f.write(f'Max. Length: \\t {stats[\"max_len\"]:,}\\n')\n",
    "    f.write(f'Avg. Length: \\t {round(stats[\"avg_len\"], 2):,}\\n')\n",
    "    f.write(f'Class. Range: \\t {class_ranges}\\n')\n",
    "    \n",
    "unique = sorted(list(set(ground_truth)))\n",
    "GT = list(map(lambda x: unique.index(x), ground_truth))\n",
    "print(GT)\n",
    "\n",
    "#2 Feature Extraction \n",
    "# Read the fasta sequences\n",
    "fastas = read_nucleotide_sequences(fasta_file)\n",
    "# Generate Kmer encodings\n",
    "encodings = Kmer(fastas, k=kmer, type='DNA', upto=False, normalize=True)\n",
    "# Save the encodings to a file\n",
    "output = 'encoding.txt'\n",
    "save_file(encodings, 'svm', output)\n",
    "# Preprocess the saved file\n",
    "with open(output, 'r') as f:\n",
    "    values_list = preprocess(f)\n",
    "# Define the output file path\n",
    "output_file = f'{name}_Kmer_{kmer}.txt'\n",
    "# Preprocess the saved file\n",
    "with open(output, 'r') as f:\n",
    "    values_list = preprocess(f)\n",
    "# Write values_list to the file with comma delimiter\n",
    "np.savetxt(output_file, values_list, delimiter=',')\n",
    "os.remove(output)\n",
    "\n",
    "#3 PCA \n",
    "X_scale, X_scale_pca, pca_components_,exp_var_pca,total_explained_variance,pca =run_pca(values_list,n_components)\n",
    "X_scale_pca\n",
    "df_pca = pd.DataFrame( X_scale_pca[:, :n_components], columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "df_pca['Label'] = GT\n",
    "\n",
    "#4 Normalized to 0-10\n",
    "scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "\n",
    "# Fit and transform the data\n",
    "X_normalized = scaler.fit_transform(X_scale_pca)\n",
    "countx=X_normalized.shape[0]\n",
    "print(countx)\n",
    "\n",
    "top_components =n_components\n",
    "df_pca_norm= pd.DataFrame(X_normalized[:, :top_components], columns=[f'PC{i+1}' for i in range(top_components)])\n",
    "df_pca_norm['Label'] = GT\n",
    "\n",
    "# feature of real data in the X_normalized\n",
    "with open(f\"{paths}/preprocessed_data.txt\", \"w\") as f:\n",
    "    np.savetxt(f,X_normalized, delimiter=\",\")\n",
    "\n",
    "# 5 Generate Guassian-only\n",
    "Generate_guassian_make_bobs(start_gen_gaussian_train_data_set,end_gen_gaussian_train_data_set,num_real,start_cluster,max_number_of_cluster,min_size,max_size, number_dimension,0.1,1,n_real,paths)\n",
    "# print(\" \")\n",
    "\n",
    "# 6 Generate KDE-only\n",
    "Generate_real(start_gen_real_train_data_set,end_gen_real_train_data_set,X_normalized, class_ranges, n_real,GT,increase_r,max_number_of_cluster,paths)\n",
    "\n",
    "# 7 add point of each pretrain  equal to the number of points of real dataset \n",
    "train_only_add_points_before_encode_data(start_add_point_train_data_set, end_add_point_train_data_set,start_cluster,max_number_of_cluster,countx,number_dimension,paths)\n",
    "\n",
    "# # 8 add real data set and normalized into 0-1 \n",
    "prepare_test_data_add_point(f\"{paths}/preprocessed_data.txt\",max_number_of_cluster,count,number_dimension,paths)\n",
    "\n",
    "# # 9 Combine all together\n",
    "encode_train_test_pattern(start_encode_train_data_set, end_encode_train_data_set,start_cluster,max_number_of_cluster,number_dimension,paths)\n",
    "\n",
    "# # 10 Train and Test with SVRRC\n",
    "train_test(max_number_of_cluster,paths,number_dimension,n_real,start_gen_real_train_data_set,end_gen_real_train_data_set,fold_num,C_x)\n",
    "\n",
    "# 11. if you want to know the accuracy of train \n",
    "train_test_train(max_number_of_cluster,paths,number_dimension,n_real,start_gen_real_train_data_set,end_gen_real_train_data_set,fold_num,C_x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
